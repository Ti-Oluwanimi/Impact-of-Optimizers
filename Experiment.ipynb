{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. IMPORTANT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toluwani/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. LOADING & USING PYTORCH TRANSFORMS ON CIFAR10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#augmentations and transforms to be used on the train and test sets\n",
    "transform = transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(0.5),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "#applying the transforms to the train-test set\n",
    "train_ds = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_ds = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#creating the train and test loaders from their respective sets\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. CODING THE LENET-5 AND ALEXNET ARCHITECTURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Sequential):\n",
    "    def __init__(self, img_channels=3, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, img_channels=3, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=img_channels, out_channels= 96, kernel_size= 3, stride=1, padding=0 )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, stride= 1, padding= 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n",
    "        self.fc2  = nn.Linear(in_features= 4096, out_features= 4096)\n",
    "        self.fc3 = nn.Linear(in_features=4096 , out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. SETTING UP GPU AND CRITERION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #to train on GPU, else CPU\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. DEFINING THE TRAIN AND TEST FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, train_loader, test_loader, optimizer, n_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #to train on GPU, else CPU\n",
    "    # model in training mode\n",
    "    model.train()\n",
    "    train_l = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_accuracy = 0\n",
    "        train_samples = 0\n",
    "        train_loss = 0.0\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predictions = torch.argmax(output, dim=-1)\n",
    "            train_samples += predictions.size(0)\n",
    "            train_accuracy += (predictions == targets).sum()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_l.append(train_loss)\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))\n",
    "\n",
    "        test_acc = []\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            test_samples = 0\n",
    "            for data,targets in test_loader:\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "                ## Forward Pass\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores,targets)\n",
    "                predictions = torch.argmax(scores, dim=-1)\n",
    "                test_accuracy += (predictions == targets).sum()\n",
    "                test_samples += predictions.size(0)\n",
    "                test_loss += loss.item()\n",
    "            t_a = (test_accuracy / test_samples)*100\n",
    "            test_acc.append(t_a)\n",
    "            print(f\"Test Accuracy: {t_a:.3f}\") \n",
    "    return model, train_l, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(A). TRAINING LENET WITH SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.302662\n",
      "Test Accuracy: 9.960\n",
      "Epoch: 2 \tTraining Loss: 2.301677\n",
      "Test Accuracy: 11.030\n",
      "Epoch: 3 \tTraining Loss: 2.300317\n",
      "Test Accuracy: 13.350\n",
      "Epoch: 4 \tTraining Loss: 2.297900\n",
      "Test Accuracy: 16.720\n",
      "Epoch: 5 \tTraining Loss: 2.292468\n",
      "Test Accuracy: 15.600\n",
      "Epoch: 6 \tTraining Loss: 2.276850\n",
      "Test Accuracy: 13.990\n",
      "Epoch: 7 \tTraining Loss: 2.243588\n",
      "Test Accuracy: 17.860\n",
      "Epoch: 8 \tTraining Loss: 2.205465\n",
      "Test Accuracy: 21.360\n",
      "Epoch: 9 \tTraining Loss: 2.165790\n",
      "Test Accuracy: 25.480\n",
      "Epoch: 10 \tTraining Loss: 2.126352\n",
      "Test Accuracy: 25.520\n",
      "Epoch: 11 \tTraining Loss: 2.084967\n",
      "Test Accuracy: 26.970\n",
      "Epoch: 12 \tTraining Loss: 2.035487\n",
      "Test Accuracy: 28.570\n",
      "Epoch: 13 \tTraining Loss: 1.980897\n",
      "Test Accuracy: 30.650\n",
      "Epoch: 14 \tTraining Loss: 1.936250\n",
      "Test Accuracy: 32.190\n",
      "Epoch: 15 \tTraining Loss: 1.901042\n",
      "Test Accuracy: 32.680\n",
      "Epoch: 16 \tTraining Loss: 1.870411\n",
      "Test Accuracy: 34.410\n",
      "Epoch: 17 \tTraining Loss: 1.840549\n",
      "Test Accuracy: 35.400\n",
      "Epoch: 18 \tTraining Loss: 1.808490\n",
      "Test Accuracy: 36.130\n",
      "Epoch: 19 \tTraining Loss: 1.771530\n",
      "Test Accuracy: 37.960\n",
      "Epoch: 20 \tTraining Loss: 1.735806\n",
      "Test Accuracy: 38.540\n",
      "Epoch: 21 \tTraining Loss: 1.702217\n",
      "Test Accuracy: 39.270\n",
      "Epoch: 22 \tTraining Loss: 1.671191\n",
      "Test Accuracy: 39.720\n",
      "Epoch: 23 \tTraining Loss: 1.643771\n",
      "Test Accuracy: 41.220\n",
      "Epoch: 24 \tTraining Loss: 1.617931\n",
      "Test Accuracy: 41.180\n",
      "Epoch: 25 \tTraining Loss: 1.595300\n",
      "Test Accuracy: 42.750\n",
      "Epoch: 26 \tTraining Loss: 1.573393\n",
      "Test Accuracy: 42.910\n",
      "Epoch: 27 \tTraining Loss: 1.556292\n",
      "Test Accuracy: 44.410\n",
      "Epoch: 28 \tTraining Loss: 1.537736\n",
      "Test Accuracy: 45.310\n",
      "Epoch: 29 \tTraining Loss: 1.519413\n",
      "Test Accuracy: 45.930\n",
      "Epoch: 30 \tTraining Loss: 1.504608\n",
      "Test Accuracy: 46.570\n",
      "Epoch: 31 \tTraining Loss: 1.487988\n",
      "Test Accuracy: 46.300\n",
      "Epoch: 32 \tTraining Loss: 1.473691\n",
      "Test Accuracy: 46.950\n",
      "Epoch: 33 \tTraining Loss: 1.460409\n",
      "Test Accuracy: 48.170\n",
      "Epoch: 34 \tTraining Loss: 1.447435\n",
      "Test Accuracy: 48.640\n",
      "Epoch: 35 \tTraining Loss: 1.433587\n",
      "Test Accuracy: 48.080\n",
      "Epoch: 36 \tTraining Loss: 1.420419\n",
      "Test Accuracy: 49.670\n",
      "Epoch: 37 \tTraining Loss: 1.407705\n",
      "Test Accuracy: 50.060\n",
      "Epoch: 38 \tTraining Loss: 1.397355\n",
      "Test Accuracy: 50.380\n",
      "Epoch: 39 \tTraining Loss: 1.387611\n",
      "Test Accuracy: 50.140\n",
      "Epoch: 40 \tTraining Loss: 1.376713\n",
      "Test Accuracy: 50.910\n",
      "Epoch: 41 \tTraining Loss: 1.367204\n",
      "Test Accuracy: 51.440\n",
      "Epoch: 42 \tTraining Loss: 1.357353\n",
      "Test Accuracy: 51.350\n",
      "Epoch: 43 \tTraining Loss: 1.347973\n",
      "Test Accuracy: 51.890\n",
      "Epoch: 44 \tTraining Loss: 1.338903\n",
      "Test Accuracy: 51.950\n",
      "Epoch: 45 \tTraining Loss: 1.332659\n",
      "Test Accuracy: 52.080\n",
      "Epoch: 46 \tTraining Loss: 1.324419\n",
      "Test Accuracy: 51.720\n",
      "Epoch: 47 \tTraining Loss: 1.318166\n",
      "Test Accuracy: 52.830\n",
      "Epoch: 48 \tTraining Loss: 1.309603\n",
      "Test Accuracy: 52.840\n",
      "Epoch: 49 \tTraining Loss: 1.303101\n",
      "Test Accuracy: 53.580\n",
      "Epoch: 50 \tTraining Loss: 1.295068\n",
      "Test Accuracy: 53.220\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "sgd_lenet = optim.SGD(lenet.parameters(), lr=1e-3) #SGD\n",
    "lenet_sgd, loss_sgd, acc_sgd = train_test(lenet, train_dl, test_dl, sgd_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(B). TRAINING LENET WITH SGD+MOMENTUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.275044\n",
      "Test Accuracy: 24.660\n",
      "Epoch: 2 \tTraining Loss: 1.915141\n",
      "Test Accuracy: 37.270\n",
      "Epoch: 3 \tTraining Loss: 1.638493\n",
      "Test Accuracy: 43.450\n",
      "Epoch: 4 \tTraining Loss: 1.483431\n",
      "Test Accuracy: 47.670\n",
      "Epoch: 5 \tTraining Loss: 1.402135\n",
      "Test Accuracy: 51.040\n",
      "Epoch: 6 \tTraining Loss: 1.332108\n",
      "Test Accuracy: 53.140\n",
      "Epoch: 7 \tTraining Loss: 1.274037\n",
      "Test Accuracy: 54.520\n",
      "Epoch: 8 \tTraining Loss: 1.223176\n",
      "Test Accuracy: 56.460\n",
      "Epoch: 9 \tTraining Loss: 1.180314\n",
      "Test Accuracy: 57.680\n",
      "Epoch: 10 \tTraining Loss: 1.141949\n",
      "Test Accuracy: 58.640\n",
      "Epoch: 11 \tTraining Loss: 1.108482\n",
      "Test Accuracy: 60.370\n",
      "Epoch: 12 \tTraining Loss: 1.073304\n",
      "Test Accuracy: 62.230\n",
      "Epoch: 13 \tTraining Loss: 1.046016\n",
      "Test Accuracy: 62.060\n",
      "Epoch: 14 \tTraining Loss: 1.022788\n",
      "Test Accuracy: 61.530\n",
      "Epoch: 15 \tTraining Loss: 0.999831\n",
      "Test Accuracy: 62.640\n",
      "Epoch: 16 \tTraining Loss: 0.974984\n",
      "Test Accuracy: 63.590\n",
      "Epoch: 17 \tTraining Loss: 0.958476\n",
      "Test Accuracy: 64.170\n",
      "Epoch: 18 \tTraining Loss: 0.935733\n",
      "Test Accuracy: 64.760\n",
      "Epoch: 19 \tTraining Loss: 0.918971\n",
      "Test Accuracy: 65.260\n",
      "Epoch: 20 \tTraining Loss: 0.903667\n",
      "Test Accuracy: 65.740\n",
      "Epoch: 21 \tTraining Loss: 0.886217\n",
      "Test Accuracy: 66.050\n",
      "Epoch: 22 \tTraining Loss: 0.874404\n",
      "Test Accuracy: 65.330\n",
      "Epoch: 23 \tTraining Loss: 0.858028\n",
      "Test Accuracy: 66.450\n",
      "Epoch: 24 \tTraining Loss: 0.843972\n",
      "Test Accuracy: 66.310\n",
      "Epoch: 25 \tTraining Loss: 0.834762\n",
      "Test Accuracy: 67.290\n",
      "Epoch: 26 \tTraining Loss: 0.816985\n",
      "Test Accuracy: 67.350\n",
      "Epoch: 27 \tTraining Loss: 0.809903\n",
      "Test Accuracy: 67.210\n",
      "Epoch: 28 \tTraining Loss: 0.794886\n",
      "Test Accuracy: 67.680\n",
      "Epoch: 29 \tTraining Loss: 0.789105\n",
      "Test Accuracy: 67.830\n",
      "Epoch: 30 \tTraining Loss: 0.777029\n",
      "Test Accuracy: 68.350\n",
      "Epoch: 31 \tTraining Loss: 0.768709\n",
      "Test Accuracy: 67.520\n",
      "Epoch: 32 \tTraining Loss: 0.760123\n",
      "Test Accuracy: 67.630\n",
      "Epoch: 33 \tTraining Loss: 0.749352\n",
      "Test Accuracy: 68.530\n",
      "Epoch: 34 \tTraining Loss: 0.739066\n",
      "Test Accuracy: 67.330\n",
      "Epoch: 35 \tTraining Loss: 0.730534\n",
      "Test Accuracy: 67.360\n",
      "Epoch: 36 \tTraining Loss: 0.725390\n",
      "Test Accuracy: 68.290\n",
      "Epoch: 37 \tTraining Loss: 0.715940\n",
      "Test Accuracy: 68.250\n",
      "Epoch: 38 \tTraining Loss: 0.706831\n",
      "Test Accuracy: 67.000\n",
      "Epoch: 39 \tTraining Loss: 0.700442\n",
      "Test Accuracy: 68.990\n",
      "Epoch: 40 \tTraining Loss: 0.693465\n",
      "Test Accuracy: 67.400\n",
      "Epoch: 41 \tTraining Loss: 0.681612\n",
      "Test Accuracy: 68.330\n",
      "Epoch: 42 \tTraining Loss: 0.680098\n",
      "Test Accuracy: 68.940\n",
      "Epoch: 43 \tTraining Loss: 0.669947\n",
      "Test Accuracy: 68.270\n",
      "Epoch: 44 \tTraining Loss: 0.663554\n",
      "Test Accuracy: 68.370\n",
      "Epoch: 45 \tTraining Loss: 0.657330\n",
      "Test Accuracy: 68.110\n",
      "Epoch: 46 \tTraining Loss: 0.652263\n",
      "Test Accuracy: 67.270\n",
      "Epoch: 47 \tTraining Loss: 0.644419\n",
      "Test Accuracy: 68.740\n",
      "Epoch: 48 \tTraining Loss: 0.636798\n",
      "Test Accuracy: 68.090\n",
      "Epoch: 49 \tTraining Loss: 0.632885\n",
      "Test Accuracy: 68.450\n",
      "Epoch: 50 \tTraining Loss: 0.630266\n",
      "Test Accuracy: 68.560\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "sgdm_lenet = optim.SGD(lenet.parameters(), lr=1e-3, momentum=0.9) #SGD with momentum\n",
    "lenet_sgdm, loss_sgdm, acc_sgdm = train_test(lenet, train_dl, test_dl, sgdm_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(C). TRAINING LENET WITH ADAGRAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.945888\n",
      "Test Accuracy: 33.340\n",
      "Epoch: 2 \tTraining Loss: 1.824652\n",
      "Test Accuracy: 35.500\n",
      "Epoch: 3 \tTraining Loss: 1.774434\n",
      "Test Accuracy: 36.910\n",
      "Epoch: 4 \tTraining Loss: 1.736010\n",
      "Test Accuracy: 38.300\n",
      "Epoch: 5 \tTraining Loss: 1.705845\n",
      "Test Accuracy: 38.880\n",
      "Epoch: 6 \tTraining Loss: 1.680451\n",
      "Test Accuracy: 39.900\n",
      "Epoch: 7 \tTraining Loss: 1.659240\n",
      "Test Accuracy: 40.650\n",
      "Epoch: 8 \tTraining Loss: 1.641373\n",
      "Test Accuracy: 40.900\n",
      "Epoch: 9 \tTraining Loss: 1.624340\n",
      "Test Accuracy: 41.700\n",
      "Epoch: 10 \tTraining Loss: 1.610433\n",
      "Test Accuracy: 41.970\n",
      "Epoch: 11 \tTraining Loss: 1.599010\n",
      "Test Accuracy: 42.530\n",
      "Epoch: 12 \tTraining Loss: 1.587490\n",
      "Test Accuracy: 42.760\n",
      "Epoch: 13 \tTraining Loss: 1.578230\n",
      "Test Accuracy: 42.850\n",
      "Epoch: 14 \tTraining Loss: 1.568048\n",
      "Test Accuracy: 43.760\n",
      "Epoch: 15 \tTraining Loss: 1.562270\n",
      "Test Accuracy: 44.050\n",
      "Epoch: 16 \tTraining Loss: 1.552911\n",
      "Test Accuracy: 44.200\n",
      "Epoch: 17 \tTraining Loss: 1.545234\n",
      "Test Accuracy: 44.310\n",
      "Epoch: 18 \tTraining Loss: 1.538684\n",
      "Test Accuracy: 44.890\n",
      "Epoch: 19 \tTraining Loss: 1.533382\n",
      "Test Accuracy: 45.000\n",
      "Epoch: 20 \tTraining Loss: 1.526663\n",
      "Test Accuracy: 45.060\n",
      "Epoch: 21 \tTraining Loss: 1.519605\n",
      "Test Accuracy: 45.990\n",
      "Epoch: 22 \tTraining Loss: 1.513544\n",
      "Test Accuracy: 45.610\n",
      "Epoch: 23 \tTraining Loss: 1.508835\n",
      "Test Accuracy: 45.990\n",
      "Epoch: 24 \tTraining Loss: 1.504798\n",
      "Test Accuracy: 46.330\n",
      "Epoch: 25 \tTraining Loss: 1.499362\n",
      "Test Accuracy: 46.070\n",
      "Epoch: 26 \tTraining Loss: 1.495086\n",
      "Test Accuracy: 46.510\n",
      "Epoch: 27 \tTraining Loss: 1.491382\n",
      "Test Accuracy: 47.130\n",
      "Epoch: 28 \tTraining Loss: 1.487329\n",
      "Test Accuracy: 46.970\n",
      "Epoch: 29 \tTraining Loss: 1.482122\n",
      "Test Accuracy: 47.530\n",
      "Epoch: 30 \tTraining Loss: 1.479258\n",
      "Test Accuracy: 46.990\n",
      "Epoch: 31 \tTraining Loss: 1.474950\n",
      "Test Accuracy: 46.910\n",
      "Epoch: 32 \tTraining Loss: 1.472538\n",
      "Test Accuracy: 47.200\n",
      "Epoch: 33 \tTraining Loss: 1.467687\n",
      "Test Accuracy: 47.600\n",
      "Epoch: 34 \tTraining Loss: 1.466255\n",
      "Test Accuracy: 47.300\n",
      "Epoch: 35 \tTraining Loss: 1.462364\n",
      "Test Accuracy: 47.920\n",
      "Epoch: 36 \tTraining Loss: 1.460213\n",
      "Test Accuracy: 48.020\n",
      "Epoch: 37 \tTraining Loss: 1.456914\n",
      "Test Accuracy: 48.050\n",
      "Epoch: 38 \tTraining Loss: 1.455541\n",
      "Test Accuracy: 47.980\n",
      "Epoch: 39 \tTraining Loss: 1.452741\n",
      "Test Accuracy: 48.540\n",
      "Epoch: 40 \tTraining Loss: 1.450771\n",
      "Test Accuracy: 48.020\n",
      "Epoch: 41 \tTraining Loss: 1.448647\n",
      "Test Accuracy: 48.510\n",
      "Epoch: 42 \tTraining Loss: 1.446826\n",
      "Test Accuracy: 48.660\n",
      "Epoch: 43 \tTraining Loss: 1.444009\n",
      "Test Accuracy: 48.410\n",
      "Epoch: 44 \tTraining Loss: 1.441134\n",
      "Test Accuracy: 48.870\n",
      "Epoch: 45 \tTraining Loss: 1.438995\n",
      "Test Accuracy: 48.810\n",
      "Epoch: 46 \tTraining Loss: 1.437815\n",
      "Test Accuracy: 49.010\n",
      "Epoch: 47 \tTraining Loss: 1.435549\n",
      "Test Accuracy: 48.630\n",
      "Epoch: 48 \tTraining Loss: 1.434228\n",
      "Test Accuracy: 48.870\n",
      "Epoch: 49 \tTraining Loss: 1.432187\n",
      "Test Accuracy: 48.660\n",
      "Epoch: 50 \tTraining Loss: 1.429871\n",
      "Test Accuracy: 48.870\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "ag_lenet = optim.Adagrad(lenet.parameters(), lr=1e-3) #Adagrad\n",
    "lenet_ag, loss_ag, acc_ag = train_test(lenet, train_dl, test_dl, ag_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(D). TRAINING LENET WITH RMSPROP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.580341\n",
      "Test Accuracy: 49.750\n",
      "Epoch: 2 \tTraining Loss: 1.321714\n",
      "Test Accuracy: 54.290\n",
      "Epoch: 3 \tTraining Loss: 1.214585\n",
      "Test Accuracy: 58.270\n",
      "Epoch: 4 \tTraining Loss: 1.140315\n",
      "Test Accuracy: 60.780\n",
      "Epoch: 5 \tTraining Loss: 1.082767\n",
      "Test Accuracy: 61.930\n",
      "Epoch: 6 \tTraining Loss: 1.043921\n",
      "Test Accuracy: 60.070\n",
      "Epoch: 7 \tTraining Loss: 1.010773\n",
      "Test Accuracy: 63.610\n",
      "Epoch: 8 \tTraining Loss: 0.976531\n",
      "Test Accuracy: 62.990\n",
      "Epoch: 9 \tTraining Loss: 0.951289\n",
      "Test Accuracy: 63.430\n",
      "Epoch: 10 \tTraining Loss: 0.926266\n",
      "Test Accuracy: 63.840\n",
      "Epoch: 11 \tTraining Loss: 0.909135\n",
      "Test Accuracy: 63.510\n",
      "Epoch: 12 \tTraining Loss: 0.891329\n",
      "Test Accuracy: 64.070\n",
      "Epoch: 13 \tTraining Loss: 0.880349\n",
      "Test Accuracy: 63.900\n",
      "Epoch: 14 \tTraining Loss: 0.860473\n",
      "Test Accuracy: 65.340\n",
      "Epoch: 15 \tTraining Loss: 0.847475\n",
      "Test Accuracy: 62.900\n",
      "Epoch: 16 \tTraining Loss: 0.835858\n",
      "Test Accuracy: 64.990\n",
      "Epoch: 17 \tTraining Loss: 0.817067\n",
      "Test Accuracy: 63.630\n",
      "Epoch: 18 \tTraining Loss: 0.810273\n",
      "Test Accuracy: 64.780\n",
      "Epoch: 19 \tTraining Loss: 0.802082\n",
      "Test Accuracy: 65.460\n",
      "Epoch: 20 \tTraining Loss: 0.790427\n",
      "Test Accuracy: 66.290\n",
      "Epoch: 21 \tTraining Loss: 0.784300\n",
      "Test Accuracy: 67.460\n",
      "Epoch: 22 \tTraining Loss: 0.775710\n",
      "Test Accuracy: 66.840\n",
      "Epoch: 23 \tTraining Loss: 0.765828\n",
      "Test Accuracy: 66.500\n",
      "Epoch: 24 \tTraining Loss: 0.755334\n",
      "Test Accuracy: 66.330\n",
      "Epoch: 25 \tTraining Loss: 0.745299\n",
      "Test Accuracy: 66.980\n",
      "Epoch: 26 \tTraining Loss: 0.743573\n",
      "Test Accuracy: 65.930\n",
      "Epoch: 27 \tTraining Loss: 0.735200\n",
      "Test Accuracy: 66.920\n",
      "Epoch: 28 \tTraining Loss: 0.733749\n",
      "Test Accuracy: 67.050\n",
      "Epoch: 29 \tTraining Loss: 0.726882\n",
      "Test Accuracy: 65.440\n",
      "Epoch: 30 \tTraining Loss: 0.718762\n",
      "Test Accuracy: 66.630\n",
      "Epoch: 31 \tTraining Loss: 0.717637\n",
      "Test Accuracy: 64.920\n",
      "Epoch: 32 \tTraining Loss: 0.708438\n",
      "Test Accuracy: 66.240\n",
      "Epoch: 33 \tTraining Loss: 0.698746\n",
      "Test Accuracy: 65.220\n",
      "Epoch: 34 \tTraining Loss: 0.701550\n",
      "Test Accuracy: 66.820\n",
      "Epoch: 35 \tTraining Loss: 0.697876\n",
      "Test Accuracy: 66.840\n",
      "Epoch: 36 \tTraining Loss: 0.686770\n",
      "Test Accuracy: 66.920\n",
      "Epoch: 37 \tTraining Loss: 0.683846\n",
      "Test Accuracy: 66.810\n",
      "Epoch: 38 \tTraining Loss: 0.681978\n",
      "Test Accuracy: 66.350\n",
      "Epoch: 39 \tTraining Loss: 0.677086\n",
      "Test Accuracy: 65.430\n",
      "Epoch: 40 \tTraining Loss: 0.670694\n",
      "Test Accuracy: 65.360\n",
      "Epoch: 41 \tTraining Loss: 0.669498\n",
      "Test Accuracy: 66.350\n",
      "Epoch: 42 \tTraining Loss: 0.665614\n",
      "Test Accuracy: 66.480\n",
      "Epoch: 43 \tTraining Loss: 0.663101\n",
      "Test Accuracy: 66.770\n",
      "Epoch: 44 \tTraining Loss: 0.656988\n",
      "Test Accuracy: 67.130\n",
      "Epoch: 45 \tTraining Loss: 0.656225\n",
      "Test Accuracy: 66.200\n",
      "Epoch: 46 \tTraining Loss: 0.654183\n",
      "Test Accuracy: 66.370\n",
      "Epoch: 47 \tTraining Loss: 0.646437\n",
      "Test Accuracy: 64.190\n",
      "Epoch: 48 \tTraining Loss: 0.649704\n",
      "Test Accuracy: 66.280\n",
      "Epoch: 49 \tTraining Loss: 0.641499\n",
      "Test Accuracy: 66.270\n",
      "Epoch: 50 \tTraining Loss: 0.638190\n",
      "Test Accuracy: 66.580\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "rms_lenet = optim.RMSprop(lenet.parameters(), lr=1e-3) #RMSprop\n",
    "lenet_rms, loss_rms, acc_rms = train_test(lenet, train_dl, test_dl, rms_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(E). TRAINING LENET WITH ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.603750\n",
      "Test Accuracy: 50.800\n",
      "Epoch: 2 \tTraining Loss: 1.310200\n",
      "Test Accuracy: 54.260\n",
      "Epoch: 3 \tTraining Loss: 1.198932\n",
      "Test Accuracy: 59.380\n",
      "Epoch: 4 \tTraining Loss: 1.124416\n",
      "Test Accuracy: 60.050\n",
      "Epoch: 5 \tTraining Loss: 1.070921\n",
      "Test Accuracy: 62.310\n",
      "Epoch: 6 \tTraining Loss: 1.020648\n",
      "Test Accuracy: 63.590\n",
      "Epoch: 7 \tTraining Loss: 0.985738\n",
      "Test Accuracy: 62.460\n",
      "Epoch: 8 \tTraining Loss: 0.955624\n",
      "Test Accuracy: 64.700\n",
      "Epoch: 9 \tTraining Loss: 0.921235\n",
      "Test Accuracy: 64.130\n",
      "Epoch: 10 \tTraining Loss: 0.896626\n",
      "Test Accuracy: 64.570\n",
      "Epoch: 11 \tTraining Loss: 0.877237\n",
      "Test Accuracy: 66.010\n",
      "Epoch: 12 \tTraining Loss: 0.861596\n",
      "Test Accuracy: 65.890\n",
      "Epoch: 13 \tTraining Loss: 0.845258\n",
      "Test Accuracy: 64.540\n",
      "Epoch: 14 \tTraining Loss: 0.827916\n",
      "Test Accuracy: 66.130\n",
      "Epoch: 15 \tTraining Loss: 0.808603\n",
      "Test Accuracy: 65.790\n",
      "Epoch: 16 \tTraining Loss: 0.800759\n",
      "Test Accuracy: 66.840\n",
      "Epoch: 17 \tTraining Loss: 0.782855\n",
      "Test Accuracy: 66.220\n",
      "Epoch: 18 \tTraining Loss: 0.771706\n",
      "Test Accuracy: 65.560\n",
      "Epoch: 19 \tTraining Loss: 0.760607\n",
      "Test Accuracy: 66.830\n",
      "Epoch: 20 \tTraining Loss: 0.753902\n",
      "Test Accuracy: 66.500\n",
      "Epoch: 21 \tTraining Loss: 0.747173\n",
      "Test Accuracy: 66.790\n",
      "Epoch: 22 \tTraining Loss: 0.732400\n",
      "Test Accuracy: 67.170\n",
      "Epoch: 23 \tTraining Loss: 0.727633\n",
      "Test Accuracy: 67.480\n",
      "Epoch: 24 \tTraining Loss: 0.713276\n",
      "Test Accuracy: 66.550\n",
      "Epoch: 25 \tTraining Loss: 0.709695\n",
      "Test Accuracy: 66.420\n",
      "Epoch: 26 \tTraining Loss: 0.704081\n",
      "Test Accuracy: 67.470\n",
      "Epoch: 27 \tTraining Loss: 0.694203\n",
      "Test Accuracy: 66.820\n",
      "Epoch: 28 \tTraining Loss: 0.689938\n",
      "Test Accuracy: 68.040\n",
      "Epoch: 29 \tTraining Loss: 0.685084\n",
      "Test Accuracy: 67.250\n",
      "Epoch: 30 \tTraining Loss: 0.674039\n",
      "Test Accuracy: 67.160\n",
      "Epoch: 31 \tTraining Loss: 0.670662\n",
      "Test Accuracy: 65.830\n",
      "Epoch: 32 \tTraining Loss: 0.660662\n",
      "Test Accuracy: 66.450\n",
      "Epoch: 33 \tTraining Loss: 0.657729\n",
      "Test Accuracy: 66.330\n",
      "Epoch: 34 \tTraining Loss: 0.654463\n",
      "Test Accuracy: 67.190\n",
      "Epoch: 35 \tTraining Loss: 0.647749\n",
      "Test Accuracy: 67.070\n",
      "Epoch: 36 \tTraining Loss: 0.642328\n",
      "Test Accuracy: 67.040\n",
      "Epoch: 37 \tTraining Loss: 0.634854\n",
      "Test Accuracy: 67.570\n",
      "Epoch: 38 \tTraining Loss: 0.629035\n",
      "Test Accuracy: 67.140\n",
      "Epoch: 39 \tTraining Loss: 0.629257\n",
      "Test Accuracy: 66.890\n",
      "Epoch: 40 \tTraining Loss: 0.624055\n",
      "Test Accuracy: 65.810\n",
      "Epoch: 41 \tTraining Loss: 0.620303\n",
      "Test Accuracy: 66.190\n",
      "Epoch: 42 \tTraining Loss: 0.615116\n",
      "Test Accuracy: 66.590\n",
      "Epoch: 43 \tTraining Loss: 0.616295\n",
      "Test Accuracy: 66.320\n",
      "Epoch: 44 \tTraining Loss: 0.611760\n",
      "Test Accuracy: 65.540\n",
      "Epoch: 45 \tTraining Loss: 0.604332\n",
      "Test Accuracy: 65.580\n",
      "Epoch: 46 \tTraining Loss: 0.601389\n",
      "Test Accuracy: 67.070\n",
      "Epoch: 47 \tTraining Loss: 0.595081\n",
      "Test Accuracy: 66.310\n",
      "Epoch: 48 \tTraining Loss: 0.589923\n",
      "Test Accuracy: 66.550\n",
      "Epoch: 49 \tTraining Loss: 0.583407\n",
      "Test Accuracy: 67.210\n",
      "Epoch: 50 \tTraining Loss: 0.584276\n",
      "Test Accuracy: 66.850\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "adam_lenet = optim.Adam(lenet.parameters(), lr=1e-3) #Adam\n",
    "lenet_adam, loss_adam, acc_adam = train_test(lenet, train_dl, test_dl, adam_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(F). TRAINING ALEXNET WITH SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.302507\n",
      "Test Accuracy: 10.040\n",
      "Epoch: 2 \tTraining Loss: 2.302268\n",
      "Test Accuracy: 11.660\n",
      "Epoch: 3 \tTraining Loss: 2.302011\n",
      "Test Accuracy: 19.450\n",
      "Epoch: 4 \tTraining Loss: 2.301700\n",
      "Test Accuracy: 16.410\n",
      "Epoch: 5 \tTraining Loss: 2.301288\n",
      "Test Accuracy: 15.350\n",
      "Epoch: 6 \tTraining Loss: 2.300695\n",
      "Test Accuracy: 15.230\n",
      "Epoch: 7 \tTraining Loss: 2.299758\n",
      "Test Accuracy: 18.080\n",
      "Epoch: 8 \tTraining Loss: 2.298127\n",
      "Test Accuracy: 19.710\n",
      "Epoch: 9 \tTraining Loss: 2.294870\n",
      "Test Accuracy: 21.570\n",
      "Epoch: 10 \tTraining Loss: 2.285994\n",
      "Test Accuracy: 21.410\n",
      "Epoch: 11 \tTraining Loss: 2.231183\n",
      "Test Accuracy: 23.650\n",
      "Epoch: 12 \tTraining Loss: 2.064181\n",
      "Test Accuracy: 29.530\n",
      "Epoch: 13 \tTraining Loss: 1.943910\n",
      "Test Accuracy: 31.130\n",
      "Epoch: 14 \tTraining Loss: 1.858402\n",
      "Test Accuracy: 34.620\n",
      "Epoch: 15 \tTraining Loss: 1.768393\n",
      "Test Accuracy: 36.950\n",
      "Epoch: 16 \tTraining Loss: 1.691709\n",
      "Test Accuracy: 40.070\n",
      "Epoch: 17 \tTraining Loss: 1.638838\n",
      "Test Accuracy: 40.970\n",
      "Epoch: 18 \tTraining Loss: 1.601778\n",
      "Test Accuracy: 41.410\n",
      "Epoch: 19 \tTraining Loss: 1.574990\n",
      "Test Accuracy: 43.200\n",
      "Epoch: 20 \tTraining Loss: 1.549469\n",
      "Test Accuracy: 43.370\n",
      "Epoch: 21 \tTraining Loss: 1.527397\n",
      "Test Accuracy: 42.570\n",
      "Epoch: 22 \tTraining Loss: 1.505759\n",
      "Test Accuracy: 44.690\n",
      "Epoch: 23 \tTraining Loss: 1.484290\n",
      "Test Accuracy: 45.810\n",
      "Epoch: 24 \tTraining Loss: 1.462446\n",
      "Test Accuracy: 47.390\n",
      "Epoch: 25 \tTraining Loss: 1.440895\n",
      "Test Accuracy: 46.310\n",
      "Epoch: 26 \tTraining Loss: 1.417166\n",
      "Test Accuracy: 49.450\n",
      "Epoch: 27 \tTraining Loss: 1.391279\n",
      "Test Accuracy: 47.660\n",
      "Epoch: 28 \tTraining Loss: 1.367095\n",
      "Test Accuracy: 51.180\n",
      "Epoch: 29 \tTraining Loss: 1.342402\n",
      "Test Accuracy: 52.280\n",
      "Epoch: 30 \tTraining Loss: 1.318938\n",
      "Test Accuracy: 51.320\n",
      "Epoch: 31 \tTraining Loss: 1.295490\n",
      "Test Accuracy: 54.480\n",
      "Epoch: 32 \tTraining Loss: 1.271454\n",
      "Test Accuracy: 52.880\n",
      "Epoch: 33 \tTraining Loss: 1.247699\n",
      "Test Accuracy: 56.510\n",
      "Epoch: 34 \tTraining Loss: 1.226692\n",
      "Test Accuracy: 56.530\n",
      "Epoch: 35 \tTraining Loss: 1.204137\n",
      "Test Accuracy: 57.250\n",
      "Epoch: 36 \tTraining Loss: 1.179763\n",
      "Test Accuracy: 56.110\n",
      "Epoch: 37 \tTraining Loss: 1.157546\n",
      "Test Accuracy: 58.030\n",
      "Epoch: 38 \tTraining Loss: 1.134924\n",
      "Test Accuracy: 57.810\n",
      "Epoch: 39 \tTraining Loss: 1.111212\n",
      "Test Accuracy: 60.630\n",
      "Epoch: 40 \tTraining Loss: 1.093926\n",
      "Test Accuracy: 60.330\n",
      "Epoch: 41 \tTraining Loss: 1.071999\n",
      "Test Accuracy: 61.870\n",
      "Epoch: 42 \tTraining Loss: 1.052421\n",
      "Test Accuracy: 59.960\n",
      "Epoch: 43 \tTraining Loss: 1.034422\n",
      "Test Accuracy: 58.990\n",
      "Epoch: 44 \tTraining Loss: 1.015211\n",
      "Test Accuracy: 63.210\n",
      "Epoch: 45 \tTraining Loss: 0.996103\n",
      "Test Accuracy: 63.150\n",
      "Epoch: 46 \tTraining Loss: 0.979955\n",
      "Test Accuracy: 63.060\n",
      "Epoch: 47 \tTraining Loss: 0.962490\n",
      "Test Accuracy: 62.890\n",
      "Epoch: 48 \tTraining Loss: 0.944167\n",
      "Test Accuracy: 63.400\n",
      "Epoch: 49 \tTraining Loss: 0.929235\n",
      "Test Accuracy: 65.910\n",
      "Epoch: 50 \tTraining Loss: 0.911972\n",
      "Test Accuracy: 66.080\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "sgd_alexnet = optim.SGD(alexnet.parameters(), lr=1e-3) #SGD\n",
    "alexnet_sgd, a_loss_sgd, a_acc_sgd = train_test(alexnet, train_dl, test_dl, sgd_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(G). TRAINING ALEXNET WITH SGD+MOMENTUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.299401\n",
      "Test Accuracy: 24.440\n",
      "Epoch: 2 \tTraining Loss: 1.890100\n",
      "Test Accuracy: 39.040\n",
      "Epoch: 3 \tTraining Loss: 1.517991\n",
      "Test Accuracy: 46.750\n",
      "Epoch: 4 \tTraining Loss: 1.370084\n",
      "Test Accuracy: 53.070\n",
      "Epoch: 5 \tTraining Loss: 1.252241\n",
      "Test Accuracy: 57.320\n",
      "Epoch: 6 \tTraining Loss: 1.144393\n",
      "Test Accuracy: 62.070\n",
      "Epoch: 7 \tTraining Loss: 1.030207\n",
      "Test Accuracy: 66.090\n",
      "Epoch: 8 \tTraining Loss: 0.928858\n",
      "Test Accuracy: 67.860\n",
      "Epoch: 9 \tTraining Loss: 0.834663\n",
      "Test Accuracy: 71.380\n",
      "Epoch: 10 \tTraining Loss: 0.747131\n",
      "Test Accuracy: 73.540\n",
      "Epoch: 11 \tTraining Loss: 0.670622\n",
      "Test Accuracy: 73.470\n",
      "Epoch: 12 \tTraining Loss: 0.603681\n",
      "Test Accuracy: 77.490\n",
      "Epoch: 13 \tTraining Loss: 0.544256\n",
      "Test Accuracy: 75.730\n",
      "Epoch: 14 \tTraining Loss: 0.493545\n",
      "Test Accuracy: 78.370\n",
      "Epoch: 15 \tTraining Loss: 0.433236\n",
      "Test Accuracy: 78.350\n",
      "Epoch: 16 \tTraining Loss: 0.386945\n",
      "Test Accuracy: 80.050\n",
      "Epoch: 17 \tTraining Loss: 0.334565\n",
      "Test Accuracy: 79.820\n",
      "Epoch: 18 \tTraining Loss: 0.287651\n",
      "Test Accuracy: 79.970\n",
      "Epoch: 19 \tTraining Loss: 0.239791\n",
      "Test Accuracy: 79.940\n",
      "Epoch: 20 \tTraining Loss: 0.201353\n",
      "Test Accuracy: 80.670\n",
      "Epoch: 21 \tTraining Loss: 0.163877\n",
      "Test Accuracy: 80.680\n",
      "Epoch: 22 \tTraining Loss: 0.139218\n",
      "Test Accuracy: 81.000\n",
      "Epoch: 23 \tTraining Loss: 0.106399\n",
      "Test Accuracy: 79.850\n",
      "Epoch: 24 \tTraining Loss: 0.092859\n",
      "Test Accuracy: 81.490\n",
      "Epoch: 25 \tTraining Loss: 0.077623\n",
      "Test Accuracy: 80.480\n",
      "Epoch: 26 \tTraining Loss: 0.064837\n",
      "Test Accuracy: 81.480\n",
      "Epoch: 27 \tTraining Loss: 0.054665\n",
      "Test Accuracy: 81.400\n",
      "Epoch: 28 \tTraining Loss: 0.041319\n",
      "Test Accuracy: 80.740\n",
      "Epoch: 29 \tTraining Loss: 0.042429\n",
      "Test Accuracy: 81.110\n",
      "Epoch: 30 \tTraining Loss: 0.040337\n",
      "Test Accuracy: 81.170\n",
      "Epoch: 31 \tTraining Loss: 0.029521\n",
      "Test Accuracy: 80.780\n",
      "Epoch: 32 \tTraining Loss: 0.022467\n",
      "Test Accuracy: 81.640\n",
      "Epoch: 33 \tTraining Loss: 0.023695\n",
      "Test Accuracy: 82.640\n",
      "Epoch: 34 \tTraining Loss: 0.020644\n",
      "Test Accuracy: 81.920\n",
      "Epoch: 35 \tTraining Loss: 0.020090\n",
      "Test Accuracy: 82.270\n",
      "Epoch: 36 \tTraining Loss: 0.015316\n",
      "Test Accuracy: 81.580\n",
      "Epoch: 37 \tTraining Loss: 0.016703\n",
      "Test Accuracy: 82.400\n",
      "Epoch: 38 \tTraining Loss: 0.012317\n",
      "Test Accuracy: 82.430\n",
      "Epoch: 39 \tTraining Loss: 0.014322\n",
      "Test Accuracy: 81.850\n",
      "Epoch: 40 \tTraining Loss: 0.016762\n",
      "Test Accuracy: 81.730\n",
      "Epoch: 41 \tTraining Loss: 0.012737\n",
      "Test Accuracy: 81.770\n",
      "Epoch: 42 \tTraining Loss: 0.014713\n",
      "Test Accuracy: 82.020\n",
      "Epoch: 43 \tTraining Loss: 0.010623\n",
      "Test Accuracy: 81.790\n",
      "Epoch: 44 \tTraining Loss: 0.011820\n",
      "Test Accuracy: 82.610\n",
      "Epoch: 45 \tTraining Loss: 0.009752\n",
      "Test Accuracy: 81.620\n",
      "Epoch: 46 \tTraining Loss: 0.008357\n",
      "Test Accuracy: 82.750\n",
      "Epoch: 47 \tTraining Loss: 0.005888\n",
      "Test Accuracy: 82.710\n",
      "Epoch: 48 \tTraining Loss: 0.007139\n",
      "Test Accuracy: 82.690\n",
      "Epoch: 49 \tTraining Loss: 0.004259\n",
      "Test Accuracy: 82.890\n",
      "Epoch: 50 \tTraining Loss: 0.003840\n",
      "Test Accuracy: 83.160\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "sgdm_alexnet = optim.SGD(alexnet.parameters(), lr=1e-3, momentum=0.9) #SGD+momentum\n",
    "alexnet_sgdm, a_loss_sgdm, a_acc_sgdm = train_test(alexnet, train_dl, test_dl, sgdm_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(H). TRAINING ALEXNET WITH ADAGRAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.435185\n",
      "Test Accuracy: 59.320\n",
      "Epoch: 2 \tTraining Loss: 1.010771\n",
      "Test Accuracy: 66.350\n",
      "Epoch: 3 \tTraining Loss: 0.846341\n",
      "Test Accuracy: 70.040\n",
      "Epoch: 4 \tTraining Loss: 0.741455\n",
      "Test Accuracy: 74.910\n",
      "Epoch: 5 \tTraining Loss: 0.665805\n",
      "Test Accuracy: 75.230\n",
      "Epoch: 6 \tTraining Loss: 0.606879\n",
      "Test Accuracy: 76.750\n",
      "Epoch: 7 \tTraining Loss: 0.558486\n",
      "Test Accuracy: 77.850\n",
      "Epoch: 8 \tTraining Loss: 0.517649\n",
      "Test Accuracy: 78.590\n",
      "Epoch: 9 \tTraining Loss: 0.480661\n",
      "Test Accuracy: 79.910\n",
      "Epoch: 10 \tTraining Loss: 0.448434\n",
      "Test Accuracy: 80.370\n",
      "Epoch: 11 \tTraining Loss: 0.420792\n",
      "Test Accuracy: 79.680\n",
      "Epoch: 12 \tTraining Loss: 0.395068\n",
      "Test Accuracy: 80.940\n",
      "Epoch: 13 \tTraining Loss: 0.368078\n",
      "Test Accuracy: 81.090\n",
      "Epoch: 14 \tTraining Loss: 0.345364\n",
      "Test Accuracy: 80.960\n",
      "Epoch: 15 \tTraining Loss: 0.323004\n",
      "Test Accuracy: 79.900\n",
      "Epoch: 16 \tTraining Loss: 0.299652\n",
      "Test Accuracy: 82.680\n",
      "Epoch: 17 \tTraining Loss: 0.281417\n",
      "Test Accuracy: 81.940\n",
      "Epoch: 18 \tTraining Loss: 0.260199\n",
      "Test Accuracy: 82.600\n",
      "Epoch: 19 \tTraining Loss: 0.241154\n",
      "Test Accuracy: 82.010\n",
      "Epoch: 20 \tTraining Loss: 0.222431\n",
      "Test Accuracy: 82.500\n",
      "Epoch: 21 \tTraining Loss: 0.202348\n",
      "Test Accuracy: 82.710\n",
      "Epoch: 22 \tTraining Loss: 0.187390\n",
      "Test Accuracy: 81.860\n",
      "Epoch: 23 \tTraining Loss: 0.169451\n",
      "Test Accuracy: 83.240\n",
      "Epoch: 24 \tTraining Loss: 0.153041\n",
      "Test Accuracy: 82.410\n",
      "Epoch: 25 \tTraining Loss: 0.136751\n",
      "Test Accuracy: 83.170\n",
      "Epoch: 26 \tTraining Loss: 0.123009\n",
      "Test Accuracy: 81.020\n",
      "Epoch: 27 \tTraining Loss: 0.110476\n",
      "Test Accuracy: 82.380\n",
      "Epoch: 28 \tTraining Loss: 0.095410\n",
      "Test Accuracy: 82.300\n",
      "Epoch: 29 \tTraining Loss: 0.085361\n",
      "Test Accuracy: 82.670\n",
      "Epoch: 30 \tTraining Loss: 0.074735\n",
      "Test Accuracy: 82.700\n",
      "Epoch: 31 \tTraining Loss: 0.062926\n",
      "Test Accuracy: 83.010\n",
      "Epoch: 32 \tTraining Loss: 0.055307\n",
      "Test Accuracy: 82.400\n",
      "Epoch: 33 \tTraining Loss: 0.046869\n",
      "Test Accuracy: 82.740\n",
      "Epoch: 34 \tTraining Loss: 0.039809\n",
      "Test Accuracy: 82.990\n",
      "Epoch: 35 \tTraining Loss: 0.031958\n",
      "Test Accuracy: 82.980\n",
      "Epoch: 36 \tTraining Loss: 0.026757\n",
      "Test Accuracy: 82.400\n",
      "Epoch: 37 \tTraining Loss: 0.021832\n",
      "Test Accuracy: 83.400\n",
      "Epoch: 38 \tTraining Loss: 0.017868\n",
      "Test Accuracy: 82.920\n",
      "Epoch: 39 \tTraining Loss: 0.015814\n",
      "Test Accuracy: 82.980\n",
      "Epoch: 40 \tTraining Loss: 0.012220\n",
      "Test Accuracy: 83.270\n",
      "Epoch: 41 \tTraining Loss: 0.009996\n",
      "Test Accuracy: 82.970\n",
      "Epoch: 42 \tTraining Loss: 0.008082\n",
      "Test Accuracy: 82.550\n",
      "Epoch: 43 \tTraining Loss: 0.006925\n",
      "Test Accuracy: 83.090\n",
      "Epoch: 44 \tTraining Loss: 0.005892\n",
      "Test Accuracy: 82.750\n",
      "Epoch: 45 \tTraining Loss: 0.005212\n",
      "Test Accuracy: 83.030\n",
      "Epoch: 46 \tTraining Loss: 0.004003\n",
      "Test Accuracy: 82.980\n",
      "Epoch: 47 \tTraining Loss: 0.003590\n",
      "Test Accuracy: 82.850\n",
      "Epoch: 48 \tTraining Loss: 0.003087\n",
      "Test Accuracy: 83.340\n",
      "Epoch: 49 \tTraining Loss: 0.002752\n",
      "Test Accuracy: 82.910\n",
      "Epoch: 50 \tTraining Loss: 0.002517\n",
      "Test Accuracy: 82.870\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "ag_alexnet = optim.Adagrad(alexnet.parameters(), lr=1e-3) #adagrad\n",
    "alexnet_ag, a_loss_ag, a_acc_ag = train_test(alexnet, train_dl, test_dl, ag_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(I). TRAINING ALEXNET WITH RMSPROP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 189.794975\n",
      "Test Accuracy: 44.330\n",
      "Epoch: 2 \tTraining Loss: 1.210230\n",
      "Test Accuracy: 61.910\n",
      "Epoch: 3 \tTraining Loss: 0.888632\n",
      "Test Accuracy: 70.710\n",
      "Epoch: 4 \tTraining Loss: 0.755241\n",
      "Test Accuracy: 74.140\n",
      "Epoch: 5 \tTraining Loss: 0.681165\n",
      "Test Accuracy: 73.810\n",
      "Epoch: 6 \tTraining Loss: 0.614819\n",
      "Test Accuracy: 72.070\n",
      "Epoch: 7 \tTraining Loss: 0.573376\n",
      "Test Accuracy: 74.630\n",
      "Epoch: 8 \tTraining Loss: 0.536066\n",
      "Test Accuracy: 77.830\n",
      "Epoch: 9 \tTraining Loss: 0.507477\n",
      "Test Accuracy: 76.730\n",
      "Epoch: 10 \tTraining Loss: 0.486715\n",
      "Test Accuracy: 76.830\n",
      "Epoch: 11 \tTraining Loss: 0.461421\n",
      "Test Accuracy: 76.350\n",
      "Epoch: 12 \tTraining Loss: 0.448829\n",
      "Test Accuracy: 78.860\n",
      "Epoch: 13 \tTraining Loss: 0.434223\n",
      "Test Accuracy: 77.280\n",
      "Epoch: 14 \tTraining Loss: 0.423981\n",
      "Test Accuracy: 78.300\n",
      "Epoch: 15 \tTraining Loss: 0.408822\n",
      "Test Accuracy: 77.790\n",
      "Epoch: 16 \tTraining Loss: 0.400866\n",
      "Test Accuracy: 78.620\n",
      "Epoch: 17 \tTraining Loss: 0.500559\n",
      "Test Accuracy: 80.200\n",
      "Epoch: 18 \tTraining Loss: 0.495267\n",
      "Test Accuracy: 76.250\n",
      "Epoch: 19 \tTraining Loss: 0.532356\n",
      "Test Accuracy: 80.420\n",
      "Epoch: 20 \tTraining Loss: 0.424765\n",
      "Test Accuracy: 77.080\n",
      "Epoch: 21 \tTraining Loss: 0.548005\n",
      "Test Accuracy: 75.480\n",
      "Epoch: 22 \tTraining Loss: 0.402461\n",
      "Test Accuracy: 81.150\n",
      "Epoch: 23 \tTraining Loss: 0.424834\n",
      "Test Accuracy: 80.960\n",
      "Epoch: 24 \tTraining Loss: 0.770213\n",
      "Test Accuracy: 80.090\n",
      "Epoch: 25 \tTraining Loss: 0.435683\n",
      "Test Accuracy: 76.970\n",
      "Epoch: 26 \tTraining Loss: 0.433710\n",
      "Test Accuracy: 79.330\n",
      "Epoch: 27 \tTraining Loss: 12.683257\n",
      "Test Accuracy: 60.430\n",
      "Epoch: 28 \tTraining Loss: 65.062739\n",
      "Test Accuracy: 63.210\n",
      "Epoch: 29 \tTraining Loss: 0.586146\n",
      "Test Accuracy: 77.070\n",
      "Epoch: 30 \tTraining Loss: 0.643181\n",
      "Test Accuracy: 77.950\n",
      "Epoch: 31 \tTraining Loss: 0.442520\n",
      "Test Accuracy: 76.520\n",
      "Epoch: 32 \tTraining Loss: 16.866742\n",
      "Test Accuracy: 77.900\n",
      "Epoch: 33 \tTraining Loss: 0.389238\n",
      "Test Accuracy: 78.740\n",
      "Epoch: 34 \tTraining Loss: 0.393123\n",
      "Test Accuracy: 80.820\n",
      "Epoch: 35 \tTraining Loss: 0.497309\n",
      "Test Accuracy: 69.030\n",
      "Epoch: 36 \tTraining Loss: 0.966451\n",
      "Test Accuracy: 82.190\n",
      "Epoch: 37 \tTraining Loss: 5.053701\n",
      "Test Accuracy: 78.500\n",
      "Epoch: 38 \tTraining Loss: 0.481181\n",
      "Test Accuracy: 81.270\n",
      "Epoch: 39 \tTraining Loss: 0.502671\n",
      "Test Accuracy: 79.090\n",
      "Epoch: 40 \tTraining Loss: 0.526627\n",
      "Test Accuracy: 75.630\n",
      "Epoch: 41 \tTraining Loss: 1.552131\n",
      "Test Accuracy: 80.030\n",
      "Epoch: 42 \tTraining Loss: 0.609683\n",
      "Test Accuracy: 77.770\n",
      "Epoch: 43 \tTraining Loss: 0.743211\n",
      "Test Accuracy: 73.110\n",
      "Epoch: 44 \tTraining Loss: 0.580979\n",
      "Test Accuracy: 78.440\n",
      "Epoch: 45 \tTraining Loss: 1.415719\n",
      "Test Accuracy: 58.950\n",
      "Epoch: 46 \tTraining Loss: 32.117862\n",
      "Test Accuracy: 76.720\n",
      "Epoch: 47 \tTraining Loss: 0.598029\n",
      "Test Accuracy: 60.130\n",
      "Epoch: 48 \tTraining Loss: 0.633037\n",
      "Test Accuracy: 73.890\n",
      "Epoch: 49 \tTraining Loss: 2.307193\n",
      "Test Accuracy: 56.210\n",
      "Epoch: 50 \tTraining Loss: 0.618548\n",
      "Test Accuracy: 78.500\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "rms_alexnet = optim.RMSprop(alexnet.parameters(), lr=1e-3) #rmsprop\n",
    "alexnet_rms, a_loss_rms, a_acc_rms = train_test(alexnet, train_dl, test_dl, rms_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(J). TRAINING ALEXNET WITH ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.616946\n",
      "Test Accuracy: 53.620\n",
      "Epoch: 2 \tTraining Loss: 1.160435\n",
      "Test Accuracy: 63.250\n",
      "Epoch: 3 \tTraining Loss: 0.985682\n",
      "Test Accuracy: 67.820\n",
      "Epoch: 4 \tTraining Loss: 0.870541\n",
      "Test Accuracy: 69.310\n",
      "Epoch: 5 \tTraining Loss: 0.798638\n",
      "Test Accuracy: 70.900\n",
      "Epoch: 6 \tTraining Loss: 0.737176\n",
      "Test Accuracy: 71.080\n",
      "Epoch: 7 \tTraining Loss: 0.682238\n",
      "Test Accuracy: 71.590\n",
      "Epoch: 8 \tTraining Loss: 0.632387\n",
      "Test Accuracy: 72.320\n",
      "Epoch: 9 \tTraining Loss: 0.593246\n",
      "Test Accuracy: 73.040\n",
      "Epoch: 10 \tTraining Loss: 0.554304\n",
      "Test Accuracy: 73.500\n",
      "Epoch: 11 \tTraining Loss: 0.519010\n",
      "Test Accuracy: 72.520\n",
      "Epoch: 12 \tTraining Loss: 0.481024\n",
      "Test Accuracy: 73.290\n",
      "Epoch: 13 \tTraining Loss: 0.456798\n",
      "Test Accuracy: 74.480\n",
      "Epoch: 14 \tTraining Loss: 0.419912\n",
      "Test Accuracy: 74.180\n",
      "Epoch: 15 \tTraining Loss: 0.402211\n",
      "Test Accuracy: 74.430\n",
      "Epoch: 16 \tTraining Loss: 0.378413\n",
      "Test Accuracy: 75.140\n",
      "Epoch: 17 \tTraining Loss: 0.361173\n",
      "Test Accuracy: 73.080\n",
      "Epoch: 18 \tTraining Loss: 0.333454\n",
      "Test Accuracy: 73.150\n",
      "Epoch: 19 \tTraining Loss: 0.330263\n",
      "Test Accuracy: 74.280\n",
      "Epoch: 20 \tTraining Loss: 0.310712\n",
      "Test Accuracy: 74.150\n",
      "Epoch: 21 \tTraining Loss: 0.301806\n",
      "Test Accuracy: 74.940\n",
      "Epoch: 22 \tTraining Loss: 0.285027\n",
      "Test Accuracy: 74.100\n",
      "Epoch: 23 \tTraining Loss: 0.270384\n",
      "Test Accuracy: 73.800\n",
      "Epoch: 24 \tTraining Loss: 0.273937\n",
      "Test Accuracy: 74.050\n",
      "Epoch: 25 \tTraining Loss: 0.252573\n",
      "Test Accuracy: 73.450\n",
      "Epoch: 26 \tTraining Loss: 0.254768\n",
      "Test Accuracy: 74.160\n",
      "Epoch: 27 \tTraining Loss: 0.238379\n",
      "Test Accuracy: 73.770\n",
      "Epoch: 28 \tTraining Loss: 0.239500\n",
      "Test Accuracy: 73.000\n",
      "Epoch: 29 \tTraining Loss: 0.235240\n",
      "Test Accuracy: 72.310\n",
      "Epoch: 30 \tTraining Loss: 0.225912\n",
      "Test Accuracy: 72.840\n",
      "Epoch: 31 \tTraining Loss: 0.227050\n",
      "Test Accuracy: 72.590\n",
      "Epoch: 32 \tTraining Loss: 0.235265\n",
      "Test Accuracy: 73.840\n",
      "Epoch: 33 \tTraining Loss: 0.221492\n",
      "Test Accuracy: 73.160\n",
      "Epoch: 34 \tTraining Loss: 0.211417\n",
      "Test Accuracy: 73.690\n",
      "Epoch: 35 \tTraining Loss: 0.207068\n",
      "Test Accuracy: 73.940\n",
      "Epoch: 36 \tTraining Loss: 0.220735\n",
      "Test Accuracy: 73.350\n",
      "Epoch: 37 \tTraining Loss: 0.201128\n",
      "Test Accuracy: 74.620\n",
      "Epoch: 38 \tTraining Loss: 0.207843\n",
      "Test Accuracy: 74.050\n",
      "Epoch: 39 \tTraining Loss: 0.199065\n",
      "Test Accuracy: 74.820\n",
      "Epoch: 40 \tTraining Loss: 0.190348\n",
      "Test Accuracy: 73.540\n",
      "Epoch: 41 \tTraining Loss: 0.185751\n",
      "Test Accuracy: 74.100\n",
      "Epoch: 42 \tTraining Loss: 0.187993\n",
      "Test Accuracy: 74.490\n",
      "Epoch: 43 \tTraining Loss: 0.182906\n",
      "Test Accuracy: 74.140\n",
      "Epoch: 44 \tTraining Loss: 0.180488\n",
      "Test Accuracy: 73.970\n",
      "Epoch: 45 \tTraining Loss: 0.182007\n",
      "Test Accuracy: 72.860\n",
      "Epoch: 46 \tTraining Loss: 0.174862\n",
      "Test Accuracy: 74.140\n",
      "Epoch: 47 \tTraining Loss: 0.173580\n",
      "Test Accuracy: 73.870\n",
      "Epoch: 48 \tTraining Loss: 0.170969\n",
      "Test Accuracy: 74.640\n",
      "Epoch: 49 \tTraining Loss: 0.170716\n",
      "Test Accuracy: 73.920\n",
      "Epoch: 50 \tTraining Loss: 0.162434\n",
      "Test Accuracy: 74.080\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "adam_alexnet = optim.Adam(alexnet.parameters(), lr=1e-3) #Adam\n",
    "alexnet_adam, a_loss_adam, a_acc_adam = train_test(alexnet, train_dl, test_dl, adam_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.702130\n",
      "Test Accuracy: 44.950\n",
      "Epoch: 2 \tTraining Loss: 1.396558\n",
      "Test Accuracy: 52.350\n",
      "Epoch: 3 \tTraining Loss: 1.264846\n",
      "Test Accuracy: 56.750\n",
      "Epoch: 4 \tTraining Loss: 1.163847\n",
      "Test Accuracy: 60.700\n",
      "Epoch: 5 \tTraining Loss: 1.075309\n",
      "Test Accuracy: 62.800\n",
      "Epoch: 6 \tTraining Loss: 0.998335\n",
      "Test Accuracy: 65.210\n",
      "Epoch: 7 \tTraining Loss: 0.927768\n",
      "Test Accuracy: 66.170\n",
      "Epoch: 8 \tTraining Loss: 0.871130\n",
      "Test Accuracy: 68.980\n",
      "Epoch: 9 \tTraining Loss: 0.819590\n",
      "Test Accuracy: 68.880\n",
      "Epoch: 10 \tTraining Loss: 0.772687\n",
      "Test Accuracy: 70.440\n",
      "Epoch: 11 \tTraining Loss: 0.726489\n",
      "Test Accuracy: 73.240\n",
      "Epoch: 12 \tTraining Loss: 0.684364\n",
      "Test Accuracy: 72.910\n",
      "Epoch: 13 \tTraining Loss: 0.641335\n",
      "Test Accuracy: 74.760\n",
      "Epoch: 14 \tTraining Loss: 0.599874\n",
      "Test Accuracy: 76.030\n",
      "Epoch: 15 \tTraining Loss: 0.562203\n",
      "Test Accuracy: 75.620\n",
      "Epoch: 16 \tTraining Loss: 0.523768\n",
      "Test Accuracy: 76.250\n",
      "Epoch: 17 \tTraining Loss: 0.490754\n",
      "Test Accuracy: 76.630\n",
      "Epoch: 18 \tTraining Loss: 0.457836\n",
      "Test Accuracy: 77.560\n",
      "Epoch: 19 \tTraining Loss: 0.420566\n",
      "Test Accuracy: 78.190\n",
      "Epoch: 20 \tTraining Loss: 0.386201\n",
      "Test Accuracy: 77.860\n",
      "Epoch: 21 \tTraining Loss: 0.353865\n",
      "Test Accuracy: 78.530\n",
      "Epoch: 22 \tTraining Loss: 0.319668\n",
      "Test Accuracy: 78.660\n",
      "Epoch: 23 \tTraining Loss: 0.284602\n",
      "Test Accuracy: 79.410\n",
      "Epoch: 24 \tTraining Loss: 0.257002\n",
      "Test Accuracy: 78.940\n",
      "Epoch: 25 \tTraining Loss: 0.223401\n",
      "Test Accuracy: 79.020\n",
      "Epoch: 26 \tTraining Loss: 0.194584\n",
      "Test Accuracy: 79.320\n",
      "Epoch: 27 \tTraining Loss: 0.170098\n",
      "Test Accuracy: 78.900\n",
      "Epoch: 28 \tTraining Loss: 0.146068\n",
      "Test Accuracy: 79.460\n",
      "Epoch: 29 \tTraining Loss: 0.125588\n",
      "Test Accuracy: 79.560\n",
      "Epoch: 30 \tTraining Loss: 0.107710\n",
      "Test Accuracy: 78.720\n",
      "Epoch: 31 \tTraining Loss: 0.091504\n",
      "Test Accuracy: 79.530\n",
      "Epoch: 32 \tTraining Loss: 0.084695\n",
      "Test Accuracy: 79.600\n",
      "Epoch: 33 \tTraining Loss: 0.070498\n",
      "Test Accuracy: 79.590\n",
      "Epoch: 34 \tTraining Loss: 0.063633\n",
      "Test Accuracy: 78.240\n",
      "Epoch: 35 \tTraining Loss: 0.059868\n",
      "Test Accuracy: 79.400\n",
      "Epoch: 36 \tTraining Loss: 0.046930\n",
      "Test Accuracy: 79.750\n",
      "Epoch: 37 \tTraining Loss: 0.050816\n",
      "Test Accuracy: 79.840\n",
      "Epoch: 38 \tTraining Loss: 0.045794\n",
      "Test Accuracy: 80.230\n",
      "Epoch: 39 \tTraining Loss: 0.037758\n",
      "Test Accuracy: 79.430\n",
      "Epoch: 40 \tTraining Loss: 0.038916\n",
      "Test Accuracy: 79.470\n",
      "Epoch: 41 \tTraining Loss: 0.038135\n",
      "Test Accuracy: 79.860\n",
      "Epoch: 42 \tTraining Loss: 0.033674\n",
      "Test Accuracy: 79.640\n",
      "Epoch: 43 \tTraining Loss: 0.034042\n",
      "Test Accuracy: 79.970\n",
      "Epoch: 44 \tTraining Loss: 0.027885\n",
      "Test Accuracy: 80.300\n",
      "Epoch: 45 \tTraining Loss: 0.030765\n",
      "Test Accuracy: 80.500\n",
      "Epoch: 46 \tTraining Loss: 0.027210\n",
      "Test Accuracy: 79.810\n",
      "Epoch: 47 \tTraining Loss: 0.028622\n",
      "Test Accuracy: 79.960\n",
      "Epoch: 48 \tTraining Loss: 0.027983\n",
      "Test Accuracy: 79.480\n",
      "Epoch: 49 \tTraining Loss: 0.022100\n",
      "Test Accuracy: 80.400\n",
      "Epoch: 50 \tTraining Loss: 0.027267\n",
      "Test Accuracy: 79.690\n"
     ]
    }
   ],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "adam_alexnet = optim.Adam(alexnet.parameters(), lr=1e-5) #Adam\n",
    "alexnet_adam, a_loss_adam, a_acc_adam = train_test(alexnet, train_dl, test_dl, adam_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAABebklEQVR4nO3dd3zU9f3A8dfndnKXvRNCBlkQQthDQEFUUES0de9aR61aa2tba2vFWjvsUn+1tW7r3hNQcSCiIgIyw04CZJC9x83P74/vJQQkJCEXLrl8no/H9e6+8/Ol8f393me8P0JKiaIoihK4dP4ugKIoijKwVKBXFEUJcCrQK4qiBDgV6BVFUQKcCvSKoigBTgV6RVGUAKcCvaL4gBBipBCiWQih9+W2x1GOp4UQf/D1cZWhTQV65bgJIYqFEKf1cZ9UIYQUQiw7YvlzQoglvjqvN+A5vAG1+ViBVQhxtRBida8v4iiklPullDYppduX2yqKL6hAr/jLNCHESQN8jvu9AdXW38A6EE/finKiqECv+JwQQieEuEMIsVcIUSOEeEUIEXnEZvcD9x3jGGcLITYKIeqFEF8KIcZ5lz8LjATe9T6l/7KfZR0NPALM8B6v3rv8aSHEf4QQy4QQLcBcIcRCIcS3QohGIcSBrr9AuvxSMXi/rxRC3CuE+EII0SSE+FAIEd3Xbb3rrxRC7PP+W97Vl19SQojrhBB7hBC1Qoh3hBCJ3uVCCPFPIUSl93q2CCHGetedJYQo8JalVAhxe3/+jRX/U4FeGQi3AOcCpwCJQB3w8BHb/BvIOlrAEkJMAJ4EbgCigP8C7wghzFLKK4D9wCLvU/r9xyjHj70Bbr0Q4vtH20BKuR34EfCV93jhXVZfinYzCgFWAy3AlUA4sBC4UQhx7jHOfynwAyAWMAHHCphH3VYIMQbt3+oyIAEIA5KOcZxOQohTgT8BF3r33Qe85F19BnAykOU95oVAjXfdE8ANUsoQYCzwSW/OpwxeKtArA+FHwG+klCVSSjuwBDi/4wnWqw0tiB6t4fB64L9Syq+llG4p5TOAHZjehzI8BGSiBc67gKeFEDP7eB1vSym/kFJ6pJTtUsqVUsot3u+bgRfRbmbdeUpKuUtK2Qa8Aow/jm3PB96VUq6WUjqA3wG9TVB1GfCklHKD9/+HX6P9ckkFnGg3sBxASCm3SynLvfs5gTFCiFApZZ2UckMvz6cMUirQKwMhBXjTW+1SD2wH3EDcEds9DsQJIRYdZf+fd+zvPUYy2q+D7xBCPNKlwfVOAG9wq5FSuqSUy4Dnge/18ToOHHGeaUKIT4UQVUKIBrQbWvTRdwXgYJfPrYDtOLZN7FoOKWUrh568e5KI9hTfsW+zd98kKeUnwL/QfmlVCiEeFUKEejf9PnAWsE8I8ZkQYkYvz6cMUirQKwPhAHCmlDK8y8sipSztupH3CfUe4F5AHLH/fUfsHyylfLFj1yOO86MuDa5/7KZM8ohzHLmuN8tfAN4BkqWUYWh1+90d01fKgREdX4QQQWjVWb1RhnbT7NjX6t23FEBK+ZCUchIwBq0K5xfe5d9IKRej/Rp6C+0XhjKEqUCv9JdRCGHp8jKgBcD7hBApAEKIGCHE4m72fxawAAu6LHsM+JH3CVoIIazehtAQ7/oKIP1YhRJCnC+EsHkbhs8ALkcL0kdTAYwQQph6uNYQoFZK2S6EmIpWrz7QXgMWCSFO8pZvCb2/ubwI/EAIMV4IYQb+CHwtpSwWQkzx/vsa0doe2gGPEMIkhLhMCBEmpXQCjYDH51elnFAq0Cv9tQytvr3jtQR4EC2ofiiEaALWANOOtrO3y+PvgMguy9YB16FVLdQBe4Cru+z2J+C33mqd7ho4b0V7cq0H/gpcJ6Vc2c22nwDbgINCiOpjXOuPgd97r+l3nIAnXSnlNrTG7ZfQnu6bgUq0Noue9v0IrX3ide++o4CLvatD0W6odWjVOzVo/04AVwDFQohGtOqpy3x0OYqfCDXxiKIMHUIIG9rNK1NKWeTn4ihDhHqiV5RBTgixSAgR7K1j/xuwBSj2b6mUoUQFekUZ/BajNayWoXUZvViqn+JKH6iqG0VRlACnnugVRVECnKHnTU686OhomZqa6u9iKIqiDBnr16+vllLGHG3doAz0qamprFu3zt/FUBRFGTKEEPu6W6eqbhRFUQKcCvSKoigBTgV6RVGUADco6+gVRRk+nE4nJSUltLe3+7soQ4LFYmHEiBEYjcZe76MCvaIoflVSUkJISAipqakIMdDJQIc2KSU1NTWUlJSQlpbW6/1U1Y2iKH7V3t5OVFSUCvK9IIQgKiqqz79+VKBXFMXvVJDvveP5twqoqpuHPt6NR0oMOoFBr9PevZ+NeoHJoMOo12HS6zAadJj1OkwGHcEmA8EmPcFmvfbZqEenU394iqIEhoAK9I98tpdWh9snxwo26YkJMRMXYiE21ExsiIW4UDPxYRYmpUQwIiLYJ+dRFGXo6hjcGR19rBkl/S+gAn3B7xfg8UhcHonL49He3RKX24PTI3G6PDjcHhzed6fLQ7vLQ5vDRavDTYvDTZvDRYvdTVO7i6pmO5WN7Wwra+TjhkranIduIllxNuZmxzInO5bJqREY9aoWTFGUwSlwAr3HDbtXoAtLwhSfh8nHzQ9SSprtLg7UtvHl3mo+3VnJk18U8d9VhYSYDczKjOayaSnMyhzcd3ZFUQ7X0tLChRdeSElJCW63m7vuuouQkBB+9rOfYbVamTlzJoWFhbz33nvU1NRwySWXUFpayowZMxgq2X97DPRCiGTgf0Ac2mTJj0opHzxim8uAX6HNZdkE3Cil3ORdV+xd5gZcUsrJvryAQ4XQwWvXwMQr4cw/+/7wQhBiMTIm0ciYxFCunZ1Os93FF3uqWbmzio+3V7B860EW5Sdy18LRxIZafF4GRQl097y7jYKyRp8ec0xiKHcvyu12/fvvv09iYiJLly4FoKGhgbFjx7Jq1SrS0tK45JJLDpXvnnuYNWsWv/vd71i6dClPPPGET8s6UHrz2OsCfi6lHANMB24SQow5Ypsi4BQpZR5wL/DoEevnSinHD1iQBxACokZBzZ4BO8WRbGYD83Pj+dP38lj1y7ncdloWH2w7yLy/f8YzXxbj9gyNu72iDGd5eXmsWLGCX/3qV3z++ecUFRWRnp7e2U+9a6BftWoVl19+OQALFy4kIiLCL2Xuqx6f6KWU5WgTCyOlbBJCbAeSgIIu23zZZZc1wAgfl7N3ojKg7Fu/nNpi1HPraZksHp/IXW9v5e53tvHa+hLuO28s40aE+6VMijLUHOvJe6BkZWWxYcMGli1bxm9/+1vmzZt3wssw0PpUkS2ESAUmAF8fY7MfAsu7fJfAh0KI9UKI649x7OuFEOuEEOuqqqr6UqxDojOhfh+47Me3vw+kRlv53zVT+b9LJlDR2M7ih79gyTvbaHf6pjeQoii+VVZWRnBwMJdffjm/+MUv+OKLLygsLKS4uBiAl19+uXPbk08+mRdeeAGA5cuXU1dX548i91mvG2O9s8+/DvxUSnnUSjQhxFy0QD+ry+JZUspSIUQssEIIsUNKuerIfaWUj+Kt8pk8efLx1XlEZYD0QF0xxGQf1yF8QQjBovxETsmO4e8f7OTpL4tZvaeaBy8eT25imN/KpSjKd23ZsoVf/OIX6HQ6jEYj//nPfygvL2fBggVYrVamTJnSue3dd9/NJZdcQm5uLieddBIjR470Y8l7r1eBXghhRAvyz0sp3+hmm3HA48CZUsqajuVSylLve6UQ4k1gKvCdQO8TURnae/Vuvwb6DqEWI/csHstpY+L4+SubOPfhL7j9jGyum52uBmQpyiAxf/585s+ff9iy5uZmduzYgZSSm266icmTtebFqKgoPvzwQ38Us196rLoR2njbJ4DtUsp/dLPNSOAN4Aop5a4uy61CiJCOz8AZwFZfFPyoOgL9CWyQ7Y3ZmTF88NOTmZcTx5+W7+DSx9dQVt/m72IpitKNxx57jPHjx5Obm0tDQwM33HCDv4vUL715op8JXAFsEUJs9C67ExgJIKV8BPgdEAX825uHoaMbZRzwpneZAXhBSvm+Ly/gMJZQsMVBze4BO8XxirCa+M/lE3l1fQn3vLONBQ+s4g/n5XFOfqK/i6YoyhFuu+02brvtNn8Xw2d60+tmNVr/+GNtcy1w7VGWFwL5x1264xGVATV7T+gpe0sIwYWTk5mWFslPX97IT178ltW7q1hyTi7BpsAZu6YoyuASeOP2T3Bf+uOREmXl1RtmcMupGby6voRF/7ea7eW+HSSiKIrSIQADfSa0VEFbvb9LckwGvY6fn5HNcz+cRmO7i8UPf8Gza/YNmSHViqIMHQEY6DsaZAdn9c2RZmZEs/zW2cxIj+Kut7Zy43MbaGh1+rtYiqIEkMAL9NGZ2vsgbJDtTrTNzFNXT+HOs3L4aHsFZz30Oev31fq7WIqi9CA1NZXq6mp/F6NHgRfow1NA6Ad9Pf2RdDrB9SeP4rUbT0Kngwv/u4Z/fbJb5ctRFKXfAi/QG0wQkaoNmhqCxieHs/QnszkrL4G/fbiLyx//morGvs0PqShK77W0tLBw4ULy8/MZO3YsL7/8MsuWLSMnJ4dJkybxk5/8hLPPPhuAmpoazjjjDHJzc7n22ms729SKi4vJycnh6quvJisri8suu4yPPvqImTNnkpmZydq1a/15iQGUj76rQdzFsjdCLUYeung8szOiufudbZz54Of87YJxnJoT5++iKcrAWn4HHNzi22PG5x0zdbmv0hTv2bOHV199lSeffJIpU6bwwgsvsHr1at555x3++Mc/8tZbb/n2uvog8J7oQQv0tXvB4/F3SY6bEIILpyTz7i2ziA0xc83T6/j9uwXYXSo5mqL4kq/SFKelpZGXl4dOpyM3N5d58+YhhCAvL68zQZq/BOYTfXQGOFuhqQzC/JMx2VcyYm28ddNM/rRsO09+UcT6fbU8fNlENWetEpgGYNKgnvgqTbHZbO78rNPpOr/rdDpcLpdPynq8AveJHoZcg2x3LEY99yweyyOXT6KwqoWFD63m0x2V/i6WogQElaZ4qIrydrGs3g3pc/xaFF9aMDaenPgQbnx+Az94+htunpvBbadnoVeZMBXluA2HNMViMI7EnDx5sly3bt3xH0BK+GPSgM0f62/tTjd3v72Nl9cd4KRRUTx48QRiQsw976gog9D27dsZPXq0v4txmObmZmw2W2ea4szMzEGV5Oxo/2ZCiPXdTdcamFU3nfPHDs0ulj2xGPX85fxx/PX8cazfV8dCNcBKUXwq0NIUB2agB22EbIDU0XfngsnJvHXTTIJNei597Gs+Kqjwd5EUJSDcdtttbNy4kYKCAp5//nmCg4d254fADfRRGVC/36/zx54IoxNCeePHM8mJD+GG59bz6roD/i6SoiiDTAAH+kxt/tjaIn+XZMBFWk28cN10ThoVxS9e28x/Pxu6g8UURfG9AA70o7T3AK++6WA1G3j8qsksHJfAn5bv4E/LtquUx4qiAIHavRK69KUPzAbZozEb9Dx08QQigo38d1UhNS0O/vy9PAz6wL2fK4rSs8CNAJ3zxw6PJ/oOep3g3sVjuXVeJq+tL+HG5zfgcA3dVBCKMhg8/fTT3HzzzSf0nCtXruxMptZfgRvoQXuqrx5egR60PDm3nZ7FkkVjWFFQwU0vqGCvKIOBlBKPH3Jw9RjohRDJQohPhRAFQohtQohbj7KNEEI8JITYI4TYLISY2GXdVUKI3d7XVb6+gGOKyhh2T/RdXT0zjXvOyWVFQQW3vLgBp1sFe0U5mnPPPZdJkyaRm5vLo48+CsBTTz1FVlYWU6dO5Ysvvujc9t1332XatGlMmDCB0047jYoKrVtzVVUVp59+emcK45SUFKqrqykuLiY7O5srr7ySsWPHcuDAAW688UYmT55Mbm4ud999d+ex33//fXJycpg4cSJvvPGGz66vN3X0LuDnUsoNQogQYL0QYoWUsqDLNmcCmd7XNOA/wDQhRCRwNzAZkN5935FSnpgEEVEZ0FoNbXUQFNHz9gHoqpNS8UjJPe8W8JMXv+WhSyZgVHX2yiD1l7V/YUftDp8eMycyh19N/dUxt3nyySeJjIykra2NKVOmsHDhQu6++27Wr19PWFgYc+fOZcKECQDMmjWLNWvWIITg8ccf5/777+fvf/8799xzD6eeeiq//vWvef/99w9LYbx7926eeeYZpk+fDsB9991HZGQkbrebefPmsXnzZrKysrjuuuv45JNPyMjI4KKLLvLZv0GP/8VLKcullBu8n5uA7UDSEZstBv4nNWuAcCFEAjAfWCGlrPUG9xXAAp+Vvied0woO7+6GP5iZxm8Xjmb51oP89KWNuNSTvaIc5qGHHiI/P5/p06dz4MABnn32WebMmUNMTAwmk+mwoFtSUsL8+fPJy8vjr3/9K9u2bQNg9erVXHzxxQAsWLDgsBTGKSkpnUEe4JVXXmHixIlMmDCBbdu2UVBQwI4dO0hLSyMzMxMhRGc6ZF/oU68bIUQqMAH4+ohVSUDXkTol3mXdLT/asa8Hrgd8lyioaxbLEUdNATFsXDs7HSnhvmXbEQIeuGi86o2jDDo9PXkPhJUrV/LRRx/x1VdfERwczJw5c8jJyaGgoOCo299yyy387Gc/45xzzmHlypUsWbKkx3NYrdbOz0VFRfztb3/jm2++ISIigquvvpr29oGdRa7X/6ULIWzA68BPpZSNvi6IlPJRKeVkKeXkmJgY3xw0IlWbP3aITivoa9ednM4dZ+bw3uZyfvbKJtVAqyhoM0pFREQQHBzMjh07WLNmDW1tbXz22WfU1NTgdDp59dVXD9s+KUl7Xn3mmWc6l8+cOZNXXnkFgA8//LDbFMaNjY1YrVbCwsKoqKhg+fLlAOTk5FBcXMzevVoNxIsvvuiza+xVoBdCGNGC/PNSyqO1EJQCyV2+j/Au6275iaE3asF+GDfIHulHp4zilwuyeWdTGVc88TW1LQ5/F0lR/GrBggW4XC5Gjx7NHXfcwfTp00lISGDJkiXMmDGDmTNnHpYpcsmSJVxwwQVMmjSJ6OjozuV33303H374IWPHjuXVV18lPj6ekJCQ75wvPz+fCRMmkJOTw6WXXsrMmTMBsFgsPProoyxcuJCJEycSGxvrs2vsMU2xEEIAzwC1UsqfdrPNQuBm4Cy0xtiHpJRTvY2x64GOXjgbgElSymOmWux3muKunr8QGkvhxi963nYYefPbEn71+hbiQs08fuUUsuO/+wepKCfCYExTfDzsdjt6vR6DwcBXX33FjTfeyMaNGwfkXH1NU9ybOvqZwBXAFiHERu+yO4GRAFLKR4BlaEF+D9AK/MC7rlYIcS/wjXe/3/cU5H0uOhOKVmnzx+pUnXSH8yaMIDXKyvXPrud7//6CBy6ewOlj1OTjinK89u/fz4UXXojH48FkMvHYY4/5u0idegz0UsrVwDGnMJLaz4Kbuln3JPDkcZWuD+xuO6/teo2cyBwmxU06tCJqFLjaAmL+WF+bMDKCd26eyfX/W8/1z67jl/Nz+NEp6Wg/4hRF6YvMzEy+/fZbfxfjqALmEVeHjie2PMFjm4+4i3adVlD5joSwIF65YQYL8xL4y/s7+Nkrm2h1+HciY0VRfCtgAr1Rb+SSnEv4ouwLdtd1CeoBNlH4QAgy6fm/SyZw+xlZvPltKQse+Jwv91b7u1iKovhIwAR6gAuyLsCit/Dc9ucOLQyJB5NNBfoeCCG4+dRMXrp+OjoBlz72Nb9+YwuN7U5/F01RlH4KqEAfbglnccZi3tv7HtVt3ifSjvljVdVNr0xPj2L5rSdz/cnpvPzNfs74xyo+3q6mKFSUoSygAj3A5aMvx+Fx8MrOVw4tjM2Fiq3+K9QQE2TSc+dZo3njxzMJDTLww2fWcetL31LdHNjTMipKoAq4QJ8alsqcEXN4eefLtLu8w4oT8qG5ApoO+rdwQ8z45HDeu2U2t87LZOnmcub+dSX//Wwvdpfb30VTlAFzIlIJu90n9r+hgAv0AFfmXkltey1LC5dqCxLytffyTf4r1BBlMui47fQs3v/pbCanRvCn5Ts4/R+reH9ruZqqUAkYXVMJ22w2Ro0axdVXX01WVhaXXXYZH330ETNnziQzM5O1a9cC8NlnnzF+/HjGjx/PhAkTaGpqYuXKlZx88sksXLiQ7OxsfvSjH3XeNGw2Gz//+c/Jz8/nq6++4h//+Adjx45l7NixPPDAA53lyMnJ4bLLLmP06NGcf/75tLa29vv6ehwZ6w/9HRkrpeSi9y7C7rbz1uK3EI5m+FMyzL0TTvmlD0s6/Hy2q4o/vFfA7spmpqVFctfZYxibFObvYilDWNdRngf/+Efs232bptg8Oof4O+885jbFxcWkp6fz5ZdfEh8fT0ZGBt9++y25ublMmTKF/Px8nnjiCd555x2eeuop3nrrLRYtWsQdd9zBzJkzaW5uxmKxsHr1ahYsWEBBQQEpKSksWLCAG264gfPPPx8hBC+//DIXXngh69ev5+qrr2bNmjVIKZk2bRrPPfccERERpKWlsXr1ambOnMk111zDmDFjuP3227v9N+twrJGxAflEL4TgijFXUNhQyOrS1WAO0bpZqif6fjslK4blt87m3nPHsruymUX/Ws3tr26ivKHN30VTlH7pmko4LS2NvLw8dDodubm5zJs3DyEEeXl5FBcXA1oSs5/97Gc89NBD1NfXYzBo40+nTp1Keno6er2eSy65hNWrVwOg1+v5/ve/D2gpjc877zysVis2m43vfe97fP755wAkJyd35r+5/PLLO/fvj4CdHHxB6gIeWP8A/yv4H7NHzNaqbw4cmV1ZOR4GvY4rpqdwTn4iD3+6h6e/KOa9zWVcOyudG05JJ8Ri9HcRlSGqpyfvgdQ1lbDZbO78rNPpOr/rdDpcLm1A4R133MHChQtZtmwZM2fO5IMPPgD4zsjyju8WiwW9Xt9jObrbvz8C8okevAOoRl/CmvI17KzdqQX6hgPQUuPvogWMsCAjd541mo9/fgpnjInnX5/uYc5fV/Lsmn1q2kIl4O3du5e8vDx+9atfMWXKFHbs0Kqc1q5dS1FRER6Ph5dffplZs2Z9Z9/Zs2fz1ltv0draSktLC2+++SazZ88GtJw5X331FQAvvPDCUffvq4AN9KANoAoyBPFswbOHGmQPquobX0uODOahSybw9k0zGRVr4663tjL/gVWsKKhQDbZKwHrggQcYO3Ys48aNw2g0cuaZZwIwZcoUbr75ZkaPHk1aWhrnnXfed/adOHEiV199NVOnTmXatGlce+21nVMVZmdn8/DDDzN69Gjq6uq48cYb+13WgGyM7eq+Nffx2u7X+HDhK8Q8NBlOWwKzbvPJsZXvklLy0fZK/rR8O4VVLZySFcPdi8aQHmPzd9GUQSpQ0hSDNlvV3/72N957773j2r+4uJizzz6brVuPPe5HNcYe4YoxV+D2uHm26F0IT1ENsgNMCMHpY+L44Kcnc9fZY9iwr475D6ziL+/voMWukqUpij8EfKAfGTqSM9PO5KmtT/FcTKIK9CeIUa/jh7PS+Pj2UzgnP4n/rNzLvL9/xrubylR1jhKw5syZc9xP8wCpqak9Ps0fj4AP9AC/n/l75o2cx19cpTzsqUG21fu7SMNGbIiFv1+Yz+s3ziDKZuKWF7/l0se+Zl9Ni7+LpijDxrAI9Ga9mb+d8jcWx0zlkYgw/vzFXXik6hVyIk1KieSdm2dx77lj2VrWwJkPfs5za/app3tFOQGGRaAHMOgM/H72fVzZ0MgLpSv5zerf4PSoFLwnkl4nuGJ6Ch/89GQmjozgt29t5aqnvuFgQ7u/i6YoAW3YBHoAXUg8tzuD+YkpmfcK3+O2T287lPhMOWESw4P43zVT+f3iXNYW1XDGPz/jrW9L1dO9ogyQYRXoAURCPtfV1vDbab9lVckqblhxAxUtKt/6iabTCa6ckcryW08mI9bGT1/eyI+f30CNSoWsDEJPP/00N998s7+Lcdx6DPRCiCeFEJVCiKM2BQshfiGE2Oh9bRVCuIUQkd51xUKILd51vukY318J+VC9i4vSz+b+k+9ne+12vv/u9/lo30f+LtmwlBZt5dUfncQvF2Tz0fYKzvjnKt7brHrmKIov9eaJ/mlgQXcrpZR/lVKOl1KOB34NfCalrO2yyVzv+qN25D/hEvJBeqBiGwvSFvDK2a+QZEvitpW3cfeXd9Pq7H9KUKVv9DrBj+dk8O4ts0gMD+LmF77lxuc2UNWknu6VE+Pcc89l0qRJ5Obm8uijjwLw1FNPkZWVxdSpU/niiy86t3333XeZNm0aEyZM4LTTTqOiQqsRWLJkCVdddRWzZ88mJSWFN954g1/+8pfk5eWxYMECnE7/tQn2mNRMSrlKCJHay+NdArzYrxINtK656ZOnkhqWynNnPse/N/2bJ7Y8wfqK9fx59p8ZGz3Wv+UchnLiQ3nzxyfx6OeFPLBiN2v++Rn3nJPLOfmJPknspAx+n7+yi+oDzT49ZnSyjdkXZh1zmyeffJLIyEja2tqYMmUKCxcu5O6772b9+vWEhYUxd+7czhQFs2bNYs2aNQghePzxx7n//vv5+9//Dmj5bz799FMKCgqYMWMGr7/+Ovfffz/nnXceS5cu5dxzz/XptfWWz+rohRDBaE/+r3dZLIEPhRDrhRDX97D/9UKIdUKIdVVVVb4q1neFJkJwNJRv7Fxk1Bu5deKtPDH/CexuO1csu4LHNj+meuX4gUGv48dzMlh26yxSo6zc+tJGrvvfeioaVaO5MnAeeugh8vPzmT59OgcOHODZZ59lzpw5xMTEYDKZuOiiizq3LSkpYf78+eTl5fHXv/6Vbdu2da4788wzMRqN5OXl4Xa7WbBAqwzpmt7YH3yZpngR8MUR1TazpJSlQohYYIUQYoeUctXRdpZSPgo8ClquGx+W63BCaE/1RxkhOyV+Cq8teo1719zLQ98+xDt73+G2SbcxN3mueqI8wTJiQ3j9xpN4YnUhf/9wF6f9/TN+sSCby6aloNep/y8CVU9P3gNh5cqVfPTRR3z11VcEBwczZ84ccnJyKCgoOOr2t9xyCz/72c8455xzWLlyJUuWLOlc1zWdsdFo7IwbXdMb+4Mve91czBHVNlLKUu97JfAmMNWH5zt+CflQuR1c360DDjOH8deT/8q/Tv0XQghu/fRWrvngGrbVbDvKgZSBpNcJrj95FO//9GTyk8P53dvb+N5/vmRbWYO/i6YEkIaGBiIiIggODmbHjh2sWbOGtrY2PvvsM2pqanA6nbz66quHbZ+UlATAM888469i94lPAr0QIgw4BXi7yzKrECKk4zNwBuD7JA7HIyEfPC6oPPodWwjBKcmn8Po5r/Obab9hb/1eLn7vYu78/E4OtqgJxk+0tGgrz/5wKg9cNJ7SulbO+dcX/OG9ApUkTfGJBQsW4HK5GD16NHfccQfTp08nISGBJUuWMGPGDGbOnHlYpsglS5ZwwQUXMGnSJKKjo/1Y8t7rMU2xEOJFYA4QDVQAdwNGACnlI95trgYWSCkv7rJfOtpTPGhVRC9IKe/rTaF8mab4qGqL4KHxsOhBmHR1j5s3OZp4YssTPFvwLEIILsi6gCvHXEmCLWHgyqgcVUOrkz+/v4MX1+4nMczC7xblMj83TlWtDWGBlKb4ROlrmuKAz0d/VFLCn1Mg7/tw9j97vVtZcxkPb3yYZYXLAFiYvpBrxl5Denj6QJVU6cb6fbXc+cZWdlY0MTMjirvOHkNOfKi/i6UcBxXo+07lo+8NISBhXJ9TFifaErlv1n0s/d5SLsq5iA+KP2Dx24u59ZNb2VK1ZYAKqxzNpJRIlv5kFveck8u2skbOevBzfvPmFjWyVlGOYngGetDq6Q9uBXffu1Am2hK5Y+odfHD+B9ww7gbWVazj0mWXcvmyy3lz95tq0NUJYtDruOqkVFbePocrZ6Ty0jcHmPO3lTz+eSEOl8pOOpQMxpqFwep4/q2GZ9UNwOZX4Y1r4cYvIS63X4dqcbbw+q7XeXXXqxQ3FmM1Wjkr7Sy+n/V9cqP6d2yl93ZXNHHv0u2s2lVFWrSVn56WydnjElV3zEGuqKiIkJAQoqKiVFtLD6SU1NTU0NTURFpa2mHrVB390VTtgoenwLn/gfGX+uSQUkq+rfyW13e/zofFH9Lubmd05GgWZyzm9JTTiQ2O9cl5lO5JKfl0ZyX3v7+THQebtIRpp2Vy1tgEdCrgD0pOp5OSkhLa29WguN6wWCyMGDECo9F42HIV6I/G44Y/JcPEK+DMv/j88I2ORpYXLuf13a+zvXY7AsH42PGckXIGp6WcRrw13ufnVA7xeCTvbzvIP1fsYndlM9lxIdx2eiZnjIlXAV8JSCrQd+eJ+VrD7DXvD+hpChsKWVG8gg/3fciuul0A5Mfkc0bKGZw68lRGhIwY0PMPZ26PZOmWch74aBeFVS2MTgjlllMzmJ8br6p0lICiAn13lv0Svn0WflkERsvAnw8obihmxT4t6O+o3QFAdkQ280bO49SRp5IVkaXqKQeA2yN5Z1Mp//fxHgqrWxgVY+XGORksHp+IUT98+yQogUMF+u7s/QSePQ8ufBbGnDPw5zvCgcYDfHLgEz7e/zEbKzcikYywjWDuyLmclHgSE2MnEmwMPuHlCmRuj2T51nIe/nQv28sbSQoP4oZT0rlwcjIWo97fxVOU46YCfXfcLvhHDqScBBf+b+DPdwzVbdWsPLCSj/d/zNflX+P0ODEIA3kxeUyNn8rU+Knkx+Zj1pv9Ws5A0dFo+69P9rBhfz3RNjNXTE/hkqnJxIaemF93iuJLwyLQSylpqbcjhMAa3odguOwXsP4Z+MUesAyOkZWtzlY2Vm1kbfla1h5cy7aabXikB7PezJioMYyNHktedB550Xkk2ZJUVU8/SClZU1jLI5/t5bNdVRh0ggVj47nqpFQmp0Sof1tlyBgWgd7t9vDorZ+Rf2oyJ30vo/c77v8anjwDzn0Exl/Sx5KeGE2OJjZUbGDtwbVsqd5CQU0Bdrc2AjTCHHEo8MfkMTZqLOGWcP8WeIgqqm7huTX7eGXdAZraXeTEh3DljFTOnZBIsMmXGb0VxfeGRaAHePm+tQSHmFj0k/G930lKeGAcxGTB5a/3vP0g4PQ42VO3hy3VW9havZUt1VvYW78Xifb/5ciQkYyNHsu4mHGMiRpDRngGIaYQP5d66Gh1uHh7Yxn/+2of28sbCTEbOG9iEpdOG6ny6SiD1rAI9NLhYPl9KyhvDOaH/5zbtxOuuBu+/D+4fRdYh0ba0SO1OFsoqClgc9VmtlRvYUv1FipbKzvXx1vjGRU+iszwTDLCM8iIyCAjPEPV+R+DlJL1++p4/uv9LN1SjsPlYXJKBJdNH8mZYxNU460yqAyPQC8lKxbdzu4RC/nB/bMIDjX1fueDW+GRmbDw7zDl2j6WdvA62HKQnbU72VO/p/NVWF+Iw+MAwCAMpIWnkRORQ3ZkNqMjR5MdmU2YOczPJR98alscvL6+hBfW7qeouoXwYCPnjk9iwdh4pqRGqj75it8Ni0APsOHa3/CVYR6LfpLPyDFRvd9RSvj3dAiKGPDBU/7m8rg40HSAXXW72Fm7kx21O9hZu5PKtkNP/8GGYOKsccQGxxIXHNf5SglLISM8g+igofmrxxeklHy1t4bnv97PR9srsLs8RFpNnDY6lvm58czMiFZP+opfHCvQB1QLU8zoeNgNVUV1fQv0QsDY8+HTP0D9AQhPHrhC+plBZyAtLI20sDTmp87vXF7TVsPO2p3srt/NwZaDVLRWUNFawdqDa6lqrcIt3Z3bRloiteqf8AwyIzJJC0sjJTSFKEvgJ6USQnBSRjQnZUTTYnfx2a4qPth2kOVbDvLKuhKsJj1zcmJZNC6BOdmxKugrg0JAPdE3ffIJLz9bR1JuLGfePrtvO9fshf+bCKf/Hmbe2udzBzK3x01New2FDYXsqdOqgHbX7WZ3/W7aXG2d2wUbghkZOpLkkGRGhmjvCbYEEq2JJNgSAro9wOHy8FVhDR9sO8iH2w5S3ezAZjZwxpg4zs5PYFZGDCaDGoGrDJxhU3XjrKzk9ZtewjUii8v/uaDvJ350rjaX7I8+7/u+w5BHeihrLmNf4z72Ne7jQNOBzveSphJc8vA5XaMsUSTaEom3xhMbHEt0UDQxQTHEBMUQHRxNbFAsYeawIf+rwOX2sKawlnc3lfH+toM0tDkJCzJy5th4zh6XyPT0SAwq7YLiY8Om6sYYG0uorKe4zYDb6UFv7ON/THkXwAe/1lIYx2QNTCEDiE7oGBEyghEhI5iZNPOwdS6Pi4rWCsqayyhvKT/sfXfdbr4s+5IWZ8t3jhlkCCLJlkSiLZFEa2Ln5yRbEkm2pCFxIzDodczKjGZWZjT3njuW1XuqeHdTOe9uKuOlbw4QZTVxZp4W9FVDrnIi9BjohRBPAmcDlVLKsUdZPwd4GyjyLnpDSvl777oFwIOAHnhcSvln3xS7e1FxJorcOmrLW4gZ2ce+47nnwQd3wtbXYO6dA1PAYcKgM3QG5+60Olupbqumqq2KqrYqKlsqD7spbKzcSKOj8bB9bEZb53FHhIzQfiEExxNvjSfOGkekJRKdGDxPyyaDjlNz4jg1J452p5tPd1Ty3pZyXltfwnNr9hMbYuasvAROGx3H5NQIVaevDIgeq26EECcDzcD/jhHob5dSnn3Ecj2wCzgdKAG+AS6RUhb0VKj+5LopfOhplheMZM75KeSeNqrvB3j6bGgsg1vWa420il81OZooay6jtLmU0uZSSppKDntvdx8+WYVRZ+zsLRQVFEWkJZJISyRRligig7TP4eZwwsxhhJnDMOqM3Zx5YLU6XHy8vZL3Npfx6c4qHC4PFqOOaWlRzM6M5uSsGDJjbYP+14syePSr6kZKuUoIkXoc550K7JFSFnoL8RKwGOgx0PdHzKQsdFsaqdhacnyBPu98ePdWKN8IiRN8Xj6lb0JMIWRHZpMdmf2ddVJK6ux1HGw52NlTqONzZWsle+v38k37N9Tb67s/vjGEMHMY4eZwrc0gOIaY4Bhig2K1z0ExRAVFEW4Ox6Tvw9iMHgSbDCzKT2RRfiKtDhdfF9ayancVq3ZV8Yel22HpduJCzczJiuX0MXHMylTdNpXj56s6+hlCiE1AGdrT/TYgCTjQZZsSYJqPztet4HF52FpepabkOKftG30OLL0dtrymAv0gJ4TofGIfEzWm2+2cHif17fXUttdS015Dg72Bens99e312rv3VdZSxqaqTdTZ6456HKvRSoQ5gghLBOHmcCIsEYSaQgk1hxJqCiXMHNb5Hm4OJ9wcTogppMeqpGCTgbk5sczN0f5mS+vbWL27ilW7qlm2pZyX1x3AYtQxOzOG08fEMS8nlihb4PZgUnzPF4F+A5AipWwWQpwFvAVk9vUgQojrgesBRo4cedyF0YeEECoaqGhORErZ95++wZGQcRpsfQNOvxd0g6e+Vzk+Rp2x80m9N5xuJ9Vt1VS2VVLVWkVtey117XXU2+ups9dR115HdVs1e+r30OhoPGqjcged0BFm0qqJIiwRRFmiOn85RAdFd/Y8CjGFYDPasBqtJIUHcdGUkVw0ZSQOl4evi2pYUVDBRwUVrCioQCdgfHI4szJjmDkqigkjI1TXTeWY+h3opZSNXT4vE0L8WwgRDZQCXUcejfAu6+44jwKPglZH358yRcYYKWk30VTbTmhUUN8PMO5C2LUcNr0IEy7rT1GUIcioN5JgSyDBltCr7Z0eJ02OJhrtjTQ4GmiwNxz61XDEL4fChkK+Pvg1TY6mbo9n0pmwmbSgH2oKJdwSTmRkJOfOC8fhCOJAtWDvQQ//+drFw1+aMOkt5CfFMi0lgVkZSUxMikevum8qXfQ70Ash4oEKKaUUQkwFdEANUA9kCiHS0AL8xcCl/T1fb8RmxsIWqNxaQugpff5xAWPOhZGPwfu/hlFzITTR52VUAodRZ+ysQuqtdlc7Ne01VLVWUd1WTZOjiRZny2GvZmczjY5G6trrKG4opra99tAAtSCwdHmM2gZsOwBPHgA8Bky6MCLMkSSFxJISHkd0UBRmvRmT3oRJb8KoM2LUGTHpTYSYtHaKMFNYZ3WTXqfaAwJJb7pXvgjMAaKFECXA3YARQEr5CHA+cKMQwgW0ARdLrSuPSwhxM/ABWvfKJ7119wMufkombKmjYvM+Mo4n0Ot0sPhf8J+Z8O5P4dKXVQ8cxacsBkuP3U+Ppt3VTr29ngZ7A22uNtpcbbS6WmlztVHe2MD2iir2VJdT2lxJaXMDZQ172XBwM+ibQfTuh7JAdFYlWQwWggxBWAwW7bM+iCBDECGmkO+8rEYrJt2hG4lJb8KkM2HUGwkyBGE1WjHoAmrozpDRm143x5yNQ0r5L+Bf3axbBiw7vqIdv5D8MVja3qZ6Xz+eSqJGwbzfaQOoNr8M+Rf7roCKcpwsBgvxBm3cQE8ONrTzdVENXxfVsqawmsKqRhBuLCYPuUlWxiXbyE20khKjo93T9J1qpxZnC22uNtpd7bS722lob6DCXaH92nA00+xs7pwDodfl11sINgZjNVqxGq0EGYIw683ajURv6fzceXPRWw5911swG8xY9BZMetNh3816M1ajlWBj8KAaRzFYBOTtVWc2EyYaqGvsZ5bFaTdAwduw/JeQdgqE9q7OVlEGg/gwC4vHJ7F4vParobrZzrriWtYW1bG2uIZnVjXikY0Y9YIJyRFMH5XFSaOimJAZjtnQ80OSR3o6g36jo5FmZzNOjxOn24nD4zj02e2g1dX6naqpFmcL7a52Wl2t1LXXYXfbaXO1YXfbO28uxyPIENTZsB1sDO783PGyGW3YTLbOm0fXXysWg3bTMOgMGPVGjMKIUW/UvuuMBBuCMegMQ258Q0Dluunqk9ufZHvTSK574BRMQf0YFFO9R8tVnz4HLnlJVeEoAaOp3cn6fXWsKazlq73VbCltwCPBbNAxOTWC6WlRTE2LJD853C99+KWUhwX9jl8Xdreddnc7Drej83tHNVZH20ars5VmZzMtzpbDPnesd3lcPRegG3qhJ8gQ1PmyGCyHVVkZ9NpNwaQzHfq10uXXSddfKcGG4M5jdFRvjQw9vl6HwybXTVcxo6LZvklHxfo9JM8affwHis6AU++CD38Dm1+B/It8V0hF8aMQi5E52bHMydb67ze0OfmmqJYv99bw5d5q/r5iF6ClcRifHM70tEimpkUxMSX8hMyhK4ToDJK+5nA7Om8OXW8kba427C47LunC5XF1/ipxeVydN5iu+3W0jzg9TlxubfsWZwtOj/arpuM8HefwSM8xyxVpieSziz7z+fUGbKCPn5wBmw5y8Nui/gV6gOk3HqrCST8FQnquH1WUoSYsyMhpY+I4bUwcAHUtDr4prmVtUS1fF9Xyr0/34PlkDwadIDcpjCkpEUxOjWRKasSQG8DV0fvoRM6mJqXE5XHR5tYCf8cNo83VRpuz7bCU374WsFU3HpeLR3/0ASlhDZz5dx/06qzerfXCyZgHF7+gqnCUYaejqmdtUS3riuvYWFKPw6U9oabHWJmSEsnYpFDGJIYxOiHkhDz1K4cMy6obncGgNcg2+OiA0Zlw6m9hxV2w8XmYcLmPDqwoQ8ORVT12l5utpQ18U1zHuuJaPiw4yMvrtKwnQkB6tJXcxDDGJIYyJiGUnIQQYmzmIdeQGQgCNtADRITrKK4PxdNuR2fxwU/LGTfB7g9h6c8hYTzEfyeZp6IMG2aDnkkpkUxKiYRTRiGlpLyhna2lDWwra2RbWSPrimt5Z1NZ5z5RVhM5CSHkxIcyOiGU3MRQMmNtaiKWARbQgT4mPYK9m4xUrd9B3Mz8/h9Qp4fzn4RHZsMrV8D1K8Fy4ur4FGUwE0KQGB5EYngQZ+Qeaseqa3Gw42AT28sb2XGwkR0Hm3huzT7s3mofs0HHmMRQxiWFkTcinLykMEbFWFXw96GAraMHKF27h7ee3M/s3AbG3XKeD0rmte8reHohZJ8JFz2n6usVpY/cHklRdQvbyhrYUtLA5tIGtpU20OLQJqE3G3RkxNrIjg8hJz6E7PhQcuJDiA1RVT/dGZZ19ACx+akgi6naW+PbA6fM0CYR//A38OX/wcyf+Pb4ihLg9DpBRqyNjFhb54Auj0dSWN3CltJ6Csq0J//Vu6t5Y8OhXIgRwcbOap/RCSGMTgglI9amcvX3IKADvdFswEYTtXUD8Ktlxk1w4Gv4aAkkTYLUmT3uoihK93Rdgv95XaaC6Kj62emt9tl+sIkX1u6j3alV/eh1glExVrLitKd/7T2UERFB6NR8vECAB3qAiDCosofjaWlBZ7X67sBCwOKHobIAXvsB3LBK9a9XlAEQYTUxY1QUM0ZFdS5zeyTFNS3sKNfq/reXN7LxQD3vbS7v3CbYpCczLoSsWBtZcSFkxmnvCWGWYVf9E/CBPjo1nAONkoZvtxExa6pvD24JhQufhcfnwWvXwJXvgD7g/0kVxe+0p3gbo2JsLBx3KAdVs93Froomdh1s8v4KaOLTnZW8ur6kc5sQs4GMOBupUVYSwy1aA3JYkLch2UKIxT/zCA+kgI9K8eNTYXMRB9ft8X2gB4gbA4sehDeu0zJdnnm/apxVFD+xmQ1MHBnBxJERhy2vbXGwq6KJ3RVN7KpoZldFE2uLajnY2I7bc3jVbliQkfQYK+nRNtJjrIyKsZIeYyMlKrhXyd4Go4AP9LGjE4EiqvZU0c9ECN0bdyGUb4Kv/gXB0TDnVwN1JkVRjkOk1cT09Cimp0cdttzl9lDVbKesvo2y+nbK6tvYX9tKYVULq/dU8fqGksO2jwkxe38BWDq7kiaFWwb9jSDgA7013IRJOKkpbcZZXo4xYYBSDZ9+L7TVwco/QlC4luJYUZRBzaDXkRAWREJYEJNSvru+2e6iqKqFwupmiqpbKK9vp6yhjV0VTazcWUWb0925rV4nGBkZzKgYK6NibWTE2BgZGUxieBAJYRa/jgsI+EAvhCBuVDiV7TlU/vcxkpb8bmBOpNPBooegvUFLfmYJU5OVKMoQZzMbyBsRRt6I7w6MlFLS0OakpK6NvVXN7K1sZk9VM3srW1i1qxqH+1CmSp2A+FALSRHar4CUyGDSYqykRdtIi7YS1p9U6r0Q8IEeYPyZGby7p4Xtq0uILSvDmDhAc8DqDfD9J+CFC+CtH4M5FHLOGphzKYriV0IIwoNNhAebGJt0+I3A5fZQUtfGgbpWSuvaKK1v63xfv6+OdzeV0bVpIMpqIi3aSmacjT+el+fzXkHDItAnj4kkJtHCvvbTqPzPf0m6956BO5nRomW3/N9iePVquPx1SJs9cOdTFGXQMeh1pEZbSY0+epduu8vNgdo2iqpbKKpuprCqhcLqFnZXNA9I189hEeiFEExZnMmy/7Szc/V+YkpKMY3o26TMfWIOgcteg6fOhBcvhqvehaSJA3c+RVGGFLNB3zk4DOIG/Hw9tg4IIZ4UQlQKIbZ2s/4yIcRmIcQWIcSXQoj8LuuKvcs3CiH6n7ymH1LHRRMZZ2Zf8hlUP/LIwJ8wOBKueFN7f/ZcOPDNwJ9TURTlKHrTDPw0sOAY64uAU6SUecC9wKNHrJ8rpRzfXbKdE0UIwZRzMmkNjmPX6mIcJSU979RfoYlw1XsQFKlV5RT6foowRVGUnvQY6KWUq4DaY6z/UkpZ5/26Bhjho7L5XPqEGMKjzexLnk/Vv/9zYk4akQLXvK+9P38B7Fh2Ys6rKIri5euOnT8Elnf5LoEPhRDrhRDXH2tHIcT1Qoh1Qoh1VVVVPi6WRqcTTF40imZrIns/L8Sxf/+AnOc7QuLh6qUQlwsvXw6bXz0x51UURcGHgV4IMRct0HcdFjpLSjkROBO4SQhxcnf7SykflVJOllJOjomJ8VWxviNzciwhEUaKU+ZT9e8TUFffITgSrnoHRs7Q0iV888SJO7eiKMOaTwK9EGIc8DiwWErZmfxdSlnqfa8E3gQGINlM3+j0OiYvHEWTbSRFq3fj2LfvxJ3cHAKXvwaZZ8DSn8Hn/4BBOPGLoiiBpd+BXggxEngDuEJKuavLcqsQIqTjM3AGcNSeOyda9vR4bGFGilMWUPXwv0/syY1BcPHzMPb78PE98NaN4Gw7sWVQFGVY6U33yheBr4BsIUSJEOKHQogfCSF+5N3kd0AU8O8julHGAauFEJuAtcBSKeX7A3ANfaY36Jh4ZhoNIWnsW7WDli+/PMEFMML3HodT7oBNL8KT86H+BLUXKIoy7AT0nLHH4nK4efY3X2KpKmTi3scZ9dZbGKKiet7R13a+r9XZ6wxwwVOQPufEl0FRlCHvWHPGDttp1g0mPZPOSqPWkkyJJZeyX/8a6fH0vKOvZS+A61eCLRaePQ++eFDV2yuK4lPDNtAD5J2SRPLoCHZnXkDFuj3UPfusfwoSNQqu/RhGL4IVv9OmJrQ3+acsiqIEnGEd6IVOMO/qMZiCTWyfegtlf3+Qtm3b/FMYsw0ueAZOuwcK3oZHZsGBtf4pi6IoAWVYB3oAa5iZeVePoYkwCnMupOznt+NpafFPYYSAWT+Fq5eB9MCTC2DlX8Dt8k95FEUJCMM+0AOkjI0if14yByKnUtocysE/3OfnAs2AH62GvPO1GauePgvqiv1bJkVRhiwV6L1mnDuK6GQbO/N/SOXST2h49z3/FsgSBt97VOuGWbkd/jMLNr2kGmoVRekzFei99EYdZ/wwF4/exI4pN1O+5B7ad+3qeceBNu4C7ek+fiy8eQO8dCnUH/B3qRRFGUJUoO8iIt7KyRdnUWNMZF/KGRz44bUnLvHZMQuWoiVFO/33sPdTeHgafPl/qu5eUZReUYH+CDkzEsiYHMveuHlUBI1i/w+uwVlR4e9igU4PM2+Fm77Wpib88Lfw6Bw1oYmiKD1Sgf4IQgjmXpZDTEooWzKuoJwk9l/zQ1x1dT3vfCJEpMAlL8FFz0FrDTxxOrx3G7TV+7tkiqIMUirQH4UpyMA5t47Xgn3WVZS2RnDg2utwNzf7u2gaIbTBVTevhek/hvVPa9U52/3cgKwoyqCkAn03zEEGzvnJeOLSQtma8wP2V1so+dGNeNrb/V20Q8whsOCPcN2nYIuBly+DV66C5kp/l0xRlEFEBfpjMAUZWPST8cSnh7FtzA8o2u+h5NZbkQ6Hv4t2uMTxWrA/9S7YuQwenqq6YiqK0kkF+h6YLAbOviWf+FHhFOReQ+H2Foovv2Jw9MbpSm+Ek2/XumJGZWpdMZ+/QHXFVBRFBfreMFkMnH1zPgkZERSM+QHFjREUnXseDW+/zaBL8xyTrU1GvuDPsO8L+NdkeP/X0DQIeg4piuIXKtD3UkewT8qJpCD1Qsrzv0/Zr+6g7Be/xN00yDJN6vQw/Ub48RptJquv/wsP5sMHv4HmgZl4XVGUwUsF+j4wmvWcfVM+6eNj2GaeTsXF99CwfDlF555H67ff+rt43xWRAuf+G27+BnLPhTX/hgfHaamQW2p63F1RlMCgAn0f6Y065l+XS86MeLYdjObgjf9FAvsuv4LKfz4wuHrldIgaBec9AjethZyz4YuH4IGxWv/7yh3+Lp2iKANs2E4l2F/SI/ni9T1s+vgAWZOiGL3nZZrefhPjiBHE3/VbbKec4u8idq9qlzaT1ZZXwW2H9Lkw7UeQeQbo1L1fUYaiY00lqAJ9P0gpWb98H1+/U0jquGhmjWul+o/34igsJOT004n7zZ0Y4+P9XczutdTAhqdh7ePQVAYRaTD1Ohh/GQSF+7t0iqL0Qb/njBVCPCmEqBRCbO1mvRBCPCSE2COE2CyEmNhl3VVCiN3e11XHdwmDkxCCyWelcvLFWRRvqWb5Sh22h54l5rbbaF61ir1nLaTmqaeRrkGafMwaBbN/Dj/dDOc/BbY4+OBO+McYVa2jKAGkV0/0QoiTgWbgf1LKsUdZfxZwC3AWMA14UEo5TQgRCawDJgMSWA9MklIeM3HMUHmi76p4czWfPr+DtkYH408byfiJJmr+/EeaP/sMc3Y2Cff+nqBx4/xdzJ6VbYS1j8KW17RqnbSTYeoNkH2m1ptHUZRBySdVN0KIVOC9bgL9f4GVUsoXvd93AnM6XlLKG462XXeGYqAHsLc6+fKNvRSsLiMsJog5l2cTun89FX+4D1dlJRFXXE7MT25Fb7P6u6g9a6mBDc/AN09AYwmEJWv1+JOu0lIvKIoyqPS76qYXkoCuQzBLvMu6W360Ql4vhFgnhFhXVTU0+3qbg43MvTyHxbdNQAJv/3Mj6yuTSXrtLSIuuYS6Z5+jcNEimj791N9F7Zk1Cmb/DG7dBBc+C+Ep8OFv4B+58NESaDro7xIqitJLg6aLhZTyUSnlZCnl5JiYGH8Xp19GZEdw8V1TGX/6SLavLuOl+7dQPecakp97Dr3NSsmNP6bktttwDYUbmt4AY86BHyyF6z6BUXO1HjsP5MHbN2s9eBRFGdR8FehLgeQu30d4l3W3POAZTXpmfj+D8++YTHhcMJ+9sJN3lzrR3fsY0bfeSvPHn7B3wZlU/PWvOCuGSLbJpElw4TNw8zqYcIXWPfPhKfDMOdro2/pBlv9HURTAd3X0C4GbOdQY+5CUcqq3MXY90NELZwNaY2ztsc41VOvouyOlpGhjNV++sYeGqjZG5EQwZUYQ8pXHaVy+HKHXE3buYiKvuQZzWpq/i9t7LdWw9jHY+jrU7NaWxeVpDbc5Z0HCeC13vqIoA67fjbFCiBfRGlajgQrgbsAIIKV8RAghgH8BC4BW4AdSynXefa8B7vQe6j4p5VM9nS/QAn0Ht8vD1s9K+WZZEfZWF6NPSmDy1CBaX/4f9a+/gXQ4CDn9dKKuu5agvDx/F7dvqnfDzuXa68AakB4IGwlTroEJV2p1/oqiDBg1YGqQaW9xsm55MVs+KcFsNTDrgkzS0g3UPfccdS+8iKexkeBp04i69lqss2YihtpTcUsN7P4ANr4AxZ+D3gx558OUayFpYs/7K4rSZyrQD1I1pc18+twOKooaGZkbySmXZGO1eKh/+WVq//c/XBUVmEePJuqHPyR0wXyEweDvIvdd5XatemfTS+BsgaTJWsDPOQssYf4unaIEDBXoBzGPR7JlZQlr3i4EKZl2Tjrj5o5AuF00vPseNU8+iWPvXoxJSUT+4AeEnbMIfWiov4vdd+0NWrBf+5hWn68zQtpsyD5Le4Udtdetoii9pAL9ENBU285nL+5k35YaYkaGMHVRGim5UYCkeeVKah57nLZvvwWjEevUqYScfhq2U0/FGBvr76L3jZRwYC3seA92LIXavdryxAmQvRCyzoD4caoRV1H6SAX6IUJKyZ71lXz5+h6a6+xEJFiZcHoyWVPi0Rt1tG3ZQuP779P00Uc49+0HIQjKzyfk9NMIOf10TCNH+vsS+kZKqN6lBfwdS6HU+/+5LQ5GzYOMeTDqVAiO9G85FWUIUIF+iHG7PexZV8m3H+6nprSZ4DAT4+aOIHd2EharESkl9t27aVqxgqaPPsa+fTsA5jGjCZ2/gND5Z2BKTfXvRRyPpgrY+zHs+Qj2fgJtdSB0Wv/9rAUwZjFEZ/q7lIoyKKlAP0RJKTmwvZaNK/ZzYHsdRrOejMmxZE+NJzEzHKHTqjccJSU0fbiCxg/ep33TZgDM2dmELpiPbc4czJmZQ68h1+OG0g1a0N/9IZRt0JbHjIbRi7TRunFjVRWPonipQB8Aqkua2PTxAfZuqMJpd2OLMJM1NY6sqfFEJdk6t3OWldG0YgWN73+g1ekDwmLBkpODZexYgvLGYhk7FlNqKkI/hLJRNpRo1TsF78D+L7V++hFp2mQpyVNhxGQtH48K/MowpQJ9AHHa3RRtrmLX1xXsL6hFeiRRI2xkTIwlZWwU0cm2zn73zooKWtd+Q/vWrbRt3Up7QQGyrQ0AXWgooQsWEHbuYoImTBhaffWbq2BnR9D/Cpyt2nJrDIyYogX95OmQPE3L1aMow4AK9AGqtdHBnvWV7Fp7kIqiRgCCw0ykjI0iZWwUyTmRmIIOBTrpduMoLKRt6zZavvySpo8+Qra1YRw5krDF5xB2zjmYkpO7O93g5HZBZQGUfAMl67T3jnQMlnDtiT/7TK1hV/XbVwKYCvTDQEuDnf3batm3tYYDBTU42t3odIKEzDDSxsWQOi6KsJjgw/ZxN7fQtGIFDW+/TevXX4OUBE2ahG3WTIInT8Yybhw6s9lPV9QPrbXaiNyd72sjdFtrQGeA1FmQdaaWgTM6S1XzKAFFBfphxu32UFHYQPGWGoq31FBX3gJARIKVtHFRpI6LIS4tFJ3uUKBzlpXR8M67NC5fjn3nTgCE0Yhl3DiCJ08mePIkgvLzh95gLY9be8rvyMNTrV0btnht9qy0kyH9FAgfYl1TFeUIKtAPcw1VrRRvrqFoczXlu+vxeCRBIUbSxkWTPiGWETkR6A2HMla76+tp3fAtrevW0bp+He1bt4HbDYApPZ2gceMIyh+HZdw4LFlZCKPRX5fWd3XFUPgZFK3SXi3eFNERqVq2zdgxEDtae0WkqTp+ZchQgV7pZG91sn9bLYWbqti3pQan3Y3Joid1XDTpE2IYOSYKo/nw3jie1lbaNm3yvjbTtmkT7lot07QwmwmeOpXQs84i5PTT0NtsRzvt4CSllounaJVW1VOxTbsR4P1vQm+GmCxIman14U+epubNVQYtFeiVo3I53ZTsqGPvt1UUbarC3uLCYNSRlh9N1tR4knMj0eu/OzeNlBJnaWln8G/++BOcpaUIkwnbKacQunAhtjmnoLNY/HBV/eRogaqdULVDa+St2AbFX2gTpdvivH34F8PIk9TTvjKoqECv9Mjj9lC2u549G6rYu76S9hYnFpuRjEmxZE+LJy4ttNsumFJK2jdtomHpMhrfX467qhqd1Yr1pBkYR47EmJSEKSkJY1ISxsREdMHBRz3OoGVv0gZtbXsLdq8AVxsER2t1+5HpWv/9iFTtFZqonvoVv1CBXukTt8vD/oJadq09SNGmatxOD6HRFhIywgmPDSIsNpjw2GDCYoMwWQ5/qpVuN61r19KwdClt36zDWV6OdDgO20YfFYUpNRVTWirmtDRMaWna9+TkwV/f72jRgn3BW1C6XhvIJT2H1uuMEDUK0k7RunSmzgKT1W/FVYYPFeiV4+Zoc1G4sYrd6yqpKW2mpd5+2PrgUBNxaaGMmhhL2rjow/rtA0iPB1d1Nc7SUpylZThLS3Ec2I+juBhHUTHumppDGxsMWLKysOSPI2hcPkH5+ZhSUxC6QTOH/Xe5nVqwryvWXvX74OAWrbrH1QZ6E4ycDhmnQfoc7ReAOcTPhVYCkQr0is847W4aqtqor2iloaqV+opWDmyvo6Xejs4gGDkmioyJMaSOi8Yc3PPTubuxEUdREY7iYux79tK2dQvtm7fgadG6hOpCQwnKy8OUno4xPh5jQjyG+ATtPSZm8ObwcbZrqRr2fKwlaKssOLTOHAohCRCaAKFJWnVP3FgtlUNoov/KrAxpKtArA0p6JAeLGtm7oZK9GypprrOj0wuSssKJSwsjNiWE2JRQrOG9G3zVOYJ382atl8+WLTj37cPT2nr4hno9xoQETOlpmNNHYRqVjjk9HVN6OoaIiAG40n5oLIN9X2pP/41l0FQGjeXa5+aDh6p/QkdA8hSth8+IqRCXC8Yh2KitnHAq0CsnjPRIKoob2bOhkpLtddSWtyA92t+YNcxEbGoosSmhxKaGEDsyFIutd3XyUko8TU04yw/iOliOs/wgzoPlOPcfwF5YiKOoCGk/VK2kj4rCkp2NOTsbS0425pwczOnpg7MNwOXQqntK1mqTspR8Aw0HtHVCpw3misrURvNGZxz6bItVo3uVTv0O9EKIBcCDgB54XEr55yPW/xOY6/0aDMRKKcO969zAFu+6/VLKc3o6nwr0gcPpcFN9oJnK4kYq9zVSua+J+opDT+ah0RYt8KeEEpsSQlhsMNYwU2cK5t6SbjfOsjIchYXY9xZi37MH+44d2PfsOdQYbDRiHjUKy5gx3tdoLNnZ6KyDsLG0sUwL+pXbtdw91bugZu+hBG6g5e6JztaCfkyW9z1bG+ilbgDDTr8CvRBCD+wCTgdKgG+AS6SUBd1sfwswQUp5jfd7s5SyT6NoVKAPbPZWJ1X7m6jc10RlcSMV+xpprj30NK4zCEIiLIREWQiNshASFURI1KHvwWHmw9I3HIt0uXAUFdG+cxf2nTto376D9oKCzgFfCIEpLQ3L6NFYxozGnJ2DJScbQ3T0QFx6/3g80FiqBf6qXVrw73g1VxzazhwGCeMgcbw2RWPCeK0RWAX/gNbfQD8DWCKlnO/9/msAKeWfutn+S+BuKeUK73cV6JUetTY6qD7QRGN1G4017TTVtNNU205jTTttjYd3z9TpBbZILehHJlpJHh1JUlbEd0b0dkdKiauykvZtBbRvL6C9YDvtBQW4yss7t9HHRGPJzsEyOgdDTCzCbEaYTejMZu9nM/rwcMypqYPjF0FbHVTv1hp9yzdB2bfaYC+399/OHAbxedoNID5Pm5c3Jhv0g7AqSzku/Q305wMLpJTXer9fAUyTUt58lG1TgDXACCml27vMBWwEXMCfpZRvdXOe64HrAUaOHDlp3759vbo4JfC5HG6aarXg33kTqNFuCNUlzbidHnR6QUJGGMmjIxk5JoroEbY+V/+46+tp37Hz0JP/zp3Y9+wBp/OY+xkSEjCnpWJKS8eUloZxRBI6iwVhMiGMJu3dZEQXFIQhOvrE9RRyOaBqO5RthPKNUL5ZC/4ubU4C9OZDeX2iu1b9pKobwBB0IgP9r9CC/C1dliVJKUuFEOnAJ8A8KeXeY51TPdErveVyuinf08CBglr2b6+lpqQZAINZT3CoieAQI0EhJoJDTQSFmLCGm0nMCCciIbhXk61IpxNPSwseuwNpb0fa7dpnhx1XZRWO4iIcRUXYC7V3T3PzsQ+o12OMi8M4YoQ2UniENmLYlJKCKTV14HsLedxQs0cL+ge9r6qd0HTo1ww6o1bVE5GipX3oeIV430OTIGyEqgoaZI4V6HvzaFEKdJ2NYoR32dFcDNzUdYGUstT7XiiEWAlMAI4Z6BWltwxGPcmjI0keHclJaHn5S3bUUbWvidYmB62NDhqq2jhY2EBbs7MzX1lwmInknEhGjI5gRHYktoijd/0URiP68HB6UykkpcRVVYWrrAyPw4F0OJEOh/ZyOvG0tmo9hUpKcZaW0vLFF7gqKw87hj483DtqWBstbIiKBIMBYTQiDEaEUfusDw3FNGpU35PI6fTaU3tMNoy74NDy9sbv1v3X79duCC2Vh4/+BW0sQMevgdhciBujZf4MjuxbeZQTojdP9Aa0xth5aAH+G+BSKeW2I7bLAd4H0qT3oEKICKBVSmkXQkQDXwGLu2vI7aCe6JWB4PFImmraKd1VR8n2Wg7sqKO9WauWiYgPJiTKgjnYiDnY4H1pn4O9vwSs4WaCbMY+Vwkds0x2O87SMhz7inEU7+scPOYoLv7OTeBoDIkJmDMyMGdmaq+MTMwZo3ybUM7j1iZvaa7QXnX7vAnfCqByG7Q3HNrWFgcxOd50zznaZO6xOWp2rxPAF90rzwIeQOte+aSU8j4hxO+BdVLKd7zbLAEsUso7uux3EvBfwAPogAeklE/0dD4V6JUTQXok1aXNlGyvo2x3Ha2NDtpbXdhbnThaXRztPw2dThAcpgX+0OggokfYiBphIzrJRnCYyadz77qbW/A0NiBdLu3ldCKdLnA5cdXWYt+9B/vu3dh378ZRWIjsaEvQ6bSeRNlZmLOyMGdlYx6VjvR48LS04mluxtPaolVJtbQgzBb0YaHow8LQh4aiCwtDHxbWu9nFpNSqfTqCfuUOrV2gaufhXUGDIrTqnrDkw9/DR2pJ4azRqiqon9SAKUXpI+mROOxu7C1OWpsctNTbaanveLfTXG+nobKV5rpD3UItNiPRI2xEJFgJDjFhsRkJshkJCjFisWrfLTZjr7uG9qm8LheO/fux79qFfdcub3fSnThLSo77mProaIJyc7Hk5WEZm0tQXh6GqKje7ezxQMN+b+DfoQ0Aqz+gjQxuKAF7w+HbG61am0B4ivYenaVN9B47RqWD7iUV6BVlgLS3OKkpbaa6pJma0mZqSpqpq2jF2e4+6vZCgCXERHCIieBQI0Gh2ueIBCtxqaFExAejO8ocAMfL3dyMfdduHEVFWs8fqxVdsFV7t1rRWYORdjvuhkbcjQ14GhpwNzbirm/AUVxM29YtOPYW0vHzxpCYgHlUBvqQEHQ2m/dlRe89nrAEobOYEWaL9m6xoLNYtHaOyEiE3tva0d6gBfz6/VpVUEdCuLp92rvD26httELSRBgx+VDgNwaDway99GYYzEnvTiAV6BXlBHM7PbS3OGlrdtLe7KCt2Ulbk5O2JgetTQ7aGrWG4o6X26k1dhqMOqKTQ7QUESmhhMUEYQrythkEGdAbdT6tHuoNT0sL7QUFtG3ZSvvWrTiKi/G0tOBuacHT3Ixsb+/dgYRAHxGBIToaQ3QU+qhojHGxGBITMSYkYExMwpiYoDUw1xVDyTotHUTJN1rvII/r6MfVGbRU0DE53jEC3lfsGDAG+ezfYbBTgV5RBjHpkdRXtlK5r4mqfU1U7muk6kATLofnO9vqDAJzkAFruJmoJBvRIzpeIb3OG+RrnV1QW1rw2O3I9nY87XakvV373taGq64Od3U1ruoaXDU13s/VuCorD7UtdFyjzaY9/Xf0NjIaEXodQtoRwok+2OR9GdAHGdBbdOiMLvRtJYjGQnSeJnRGic4o0MWOQkSP8rYHdG0fSNYajgPo14AK9IoyxHjcHuoOttJcb8fR6sLe5m0kbnNhb3XRVKsNFmttODRq2BZhJiLBijnYgMliwGTRY/S+m4K0ZeZgg/YLIcjQ+Uuh68TwJ1rHfAWu8nKc5eXanAVlZbgbG5Eup3YTcHY0RDvxtLfjbmjA3dCAp7GRo7aYH0EfJDAGuzBYHBiD3RiDPRiC3ehNOrBFIGyxEBKDCIlFhMZCWAK6iHh0kUmIyCR01hCExTK450Wg//3oFUU5wXR6HVFJNqKSjt1Pvq3JQXVJM9UHmqkubaL+YCtNNe042l042t247EdvK+jKYjV2ySvUJbdQpJngUN93Ke1K6HQYY2MxxsYSlJ/fp32l2+1tT6jH09CAp60NT2ur9mpp1b43N+OqrMR58CDOslJayw7iaema7toDHPS+jk1n0mGMtmJKjMWUmoYpYzSm0RMxjkxBOhy4G5vwNDd1vnuam9FHRmojplNT0dv8lypDPdErSgDzuD047W7sbS4cbW7tF0GbC4f3ZW910lzvoKmmrTPFREd7QYeOLqXBYWasYSZsERbCYoIIiwkiNCaI0GgLBuPQmSfX3dyMq7wcT2sr0u0BtwvpdiNdTmiuQTZU4mmsRjZW42mqRTbV42lpxN3QgKOqEWcDOJr1IPt28zPExmoD4dJSMcbHo7OFoA8NOfQeEoo+NARjQsJxXZd6oleUYUqn12EO1vVqti/QRve2NTlprG7TupI22GlpcNDq/dxQ1UbpzjocXXsVCbB5xxXYIs3Ywi1Yw83YIrRBZtYwMzq96Dy+9kGrdTEF6b8z7/BA09ts6DMzj29nKaG1Flm1C+eODTj2bMO5vxidowadowI9LehMHvRGic4gcckI7O0hOFosOBocOMoKaNyyAU/r0fMn6cNDyVrzdT+u7uhUoFcUpZMQQssRFGrqdhspJe0tThoq22ioaqOxuo2GSu29fE8DLfWVeNy9rykwduQlCjNhDTN35iWyWA2YrdroZIvViDlYG4dgsuhPeM+jTkKANQphnYEpdQaH/St5bwLUFna+9C1VmNvqoK1WyzDa2gxttci2ZtxOHR6n0N4d2jumnqvajocK9Iqi9IkQgiCbiSCbifj076Y2kB5JW7Ozc2BZS729c5YxIbT/6YjT9lYXrQ0OWhrttDZo7Q0tDfZuxyGA1gU1OMxEcKhZuzmEmrCEmLRZyFwSj9uD2y3xuLXPpiCDd+CayfsyEmQzYQs3ozf6sIHVexPAGqVNB3msTT1uDM5WsDeDo0UbN+Bo1tJNDAAV6BVF8SmhO/SrIGZkyHEdw+V0Y291YW9x0d7qxN7ixN7qoq3JSWujndZGBy0NDuoOtlK6sw57q9bHXqcX6Aw69HqBTi8QOoGjzXXUrqodVU4dbQ1hMUFa9VOEpbNKyRRkwGjW+340s04P5hDtdQKoQK8oyqBjMOoxhOmxhvVuQnmPRyIE3VbpOO1u2po6Bq45aGty0FRrp6GqlcaqNoo3V9PW1P28A0azHnOwAVuE1hvJFmkhJNKCLdKitUWEDWzvpP5SgV5RlCGvpyduo1mP0aw9sXfH0e7yNkI7cLS7cLa7tW6qbVpX1fYWJ8117VTsa2Lvxio8rsPbIYROEBRi7GxnCA7Tqoe0rqpa11VbuMW31UW9pAK9oigKYLIYiB4RQvSInreVHklrk4PmOjvNte1azyRvO4NWrWSnar82JwJd7wcCgkNNmCwGPG4PHo9EuiUej/YKspm47J7pPr82FegVRVH6SOgE1jCtyiYuNbTb7dxOD831HXMg27UpMWvbcTnc6HQCnU4g9Nq71hV2YEKyCvSKoigDRG/UERYTTFhMsF/LMbiTNyiKoij9pgK9oihKgFOBXlEUJcCpQK8oihLgehXohRALhBA7hRB7hBB3HGX91UKIKiHERu/r2i7rrhJC7Pa+rvJl4RVFUZSe9djrRgihBx4GTgdKgG+EEO9IKQuO2PRlKeXNR+wbCdwNTEbrTbreu2+dT0qvKIqi9Kg3T/RTgT1SykIppQN4CVjcy+PPB1ZIKWu9wX0FsOD4iqooiqIcj94E+iTgQJfvJd5lR/q+EGKzEOI1IURyH/dVFEVRBoivBky9C7wopbQLIW4AngFO7csBhBDXA9d7vzYLIXYeZ1migerj3HcoU9c9vKjrHl56c90p3a3oTaAvBZK7fB/hXdZJSlnT5evjwP1d9p1zxL4rj3YSKeWjwKO9KM8xCSHWdTedViBT1z28qOseXvp73b2puvkGyBRCpAkhTMDFwDtHFKLrJIfnANu9nz8AzhBCRAghIoAzvMsURVGUE6THJ3oppUsIcTNagNYDT0optwkhfg+sk1K+A/xECHEO4AJqgau9+9YKIe5Fu1kA/F5KWTsA16EoiqJ0Q3RO1hsghBDXe6uBhhV13cOLuu7hpb/XHXCBXlEURTmcSoGgKIoS4FSgVxRFCXABE+h7yscTSIQQTwohKoUQW7ssixRCrPDmFFrh7eUUMIQQyUKIT4UQBUKIbUKIW73LA/q6AYQQFiHEWiHEJu+13+NdniaE+Nr7N/+yt1dcQBFC6IUQ3woh3vN+D/hrBhBCFAshtnhzh63zLjvuv/WACPRd8vGcCYwBLhFCjPFvqQbU03w3lcQdwMdSykzgY+/3QOICfi6lHANMB27y/n8c6NcNYAdOlVLmA+OBBUKI6cBfgH9KKTOAOuCH/ivigLmVQ921YXhcc4e5UsrxXfrPH/ffekAEevqXj2fIkVKuQuvG2tVitBHJeN/PPZFlGmhSynIp5Qbv5ya0//iTCPDrBpCaZu9Xo/cl0Uafv+ZdHnDXLoQYASxEG4SJEEIQ4Nfcg+P+Ww+UQK9y6kCclLLc+/kgEOfPwgwkIUQqMAH4mmFy3d4qjI1AJVpywL1AvZTS5d0kEP/mHwB+CXi836MI/GvuIIEPhRDrvelhoB9/62py8AAkpZRCiIDsNyuEsAGvAz+VUjZqD3maQL5uKaUbGC+ECAfeBHL8W6KBJYQ4G6iUUq4XQszxc3H8YZaUslQIEQusEELs6Lqyr3/rgfJE32M+nmGgoiMVhfe90s/l8TkhhBEtyD8vpXzDuzjgr7srKWU98CkwAwgXQnQ8rAXa3/xM4BwhRDFaVeypwIME9jV3klKWet8r0W7sU+nH33qgBPoe8/EMA+8AHTN4XQW87cey+Jy3fvYJYLuU8h9dVgX0dQMIIWK8T/IIIYLQJgHajhbwz/duFlDXLqX8tZRyhJQyFe2/50+klJcRwNfcQQhhFUKEdHxGyxG2lX78rQfMyFghxFlodXod+Xju82+JBo4Q4kW0rKDRQAXaLF5vAa8AI4F9wIWBlFdICDEL+BzYwqE62zvR6ukD9roBhBDj0Brf9GgPZ69IKX8vhEhHe9qNBL4FLpdS2v1X0oHhrbq5XUp59nC4Zu81vun9agBekFLeJ4SI4jj/1gMm0CuKoihHFyhVN4qiKEo3VKBXFEUJcCrQK4qiBDgV6BVFUQKcCvSKoigBTgV6RVGUAKcCvaIoSoD7f62zmsvWV0FlAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_sgd, label = \"sgd\")\n",
    "plt.plot(loss_sgdm, label = \"sgdm\")\n",
    "plt.plot(loss_ag, label = \"adagrad\")\n",
    "plt.plot(loss_rms, label = \"rmsprop\")\n",
    "plt.plot(loss_adam, label = \"adam\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"LeNet-5 training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77ea62aefc826ad60bd92e68cbd3f3114bc6d7e920db1ef6da6e6811c5006655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
