{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. IMPORTANT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toluwani/anaconda3/envs/pytorch/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision.datasets import CIFAR10\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. LOADING & USING PYTORCH TRANSFORMS ON CIFAR10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#augmentations and transforms to be used on the train and test sets\n",
    "transform = transforms.Compose([\n",
    "                                transforms.RandomHorizontalFlip(0.5),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                ])\n",
    "\n",
    "#applying the transforms to the train-test set\n",
    "train_ds = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "test_ds = CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#creating the train and test loaders from their respective sets\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. CODING THE LENET-5 AND ALEXNET ARCHITECTURES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Sequential):\n",
    "    def __init__(self, img_channels=3, num_classes=10):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(img_channels, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, img_channels=3, num_classes=10):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=img_channels, out_channels= 96, kernel_size= 3, stride=1, padding=0 )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=3, stride= 1, padding= 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1  = nn.Linear(in_features= 9216, out_features= 4096)\n",
    "        self.fc2  = nn.Linear(in_features= 4096, out_features= 4096)\n",
    "        self.fc3 = nn.Linear(in_features=4096 , out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. SETTING UP GPU AND CRITERION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #to train on GPU, else CPU\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. DEFINING THE TRAIN AND TEST FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, train_loader, test_loader, optimizer, n_epochs):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') #to train on GPU, else CPU\n",
    "    # model in training mode\n",
    "    model.train()\n",
    "    train_l = []\n",
    "    test_acc = []\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_accuracy = 0\n",
    "        train_samples = 0\n",
    "        train_loss = 0.0\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            predictions = torch.argmax(output, dim=-1)\n",
    "            train_samples += predictions.size(0)\n",
    "            train_accuracy += (predictions == targets).sum()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # calculate average losses\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_l.append(train_loss)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            test_accuracy = 0\n",
    "            test_samples = 0\n",
    "            for data,targets in test_loader:\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "                ## Forward Pass\n",
    "                scores = model(data)\n",
    "                loss = criterion(scores,targets)\n",
    "                predictions = torch.argmax(scores, dim=-1)\n",
    "                test_accuracy += (predictions == targets).sum()\n",
    "                test_samples += predictions.size(0)\n",
    "                test_loss += loss.item() \n",
    "            t_a = (test_accuracy / test_samples)*100\n",
    "            test_acc.append(t_a)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss), f\"  Test Accuracy: {t_a:.3f}\")\n",
    "            \n",
    "    return model, train_l, test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(A). TRAINING LENET WITH SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.303624   Test Accuracy: 9.990\n",
      "Epoch: 2 \tTraining Loss: 2.302592   Test Accuracy: 9.770\n",
      "Epoch: 3 \tTraining Loss: 2.301587   Test Accuracy: 9.890\n",
      "Epoch: 4 \tTraining Loss: 2.300380   Test Accuracy: 14.040\n",
      "Epoch: 5 \tTraining Loss: 2.298598   Test Accuracy: 18.560\n",
      "Epoch: 6 \tTraining Loss: 2.295333   Test Accuracy: 15.830\n",
      "Epoch: 7 \tTraining Loss: 2.287461   Test Accuracy: 13.420\n",
      "Epoch: 8 \tTraining Loss: 2.266315   Test Accuracy: 12.320\n",
      "Epoch: 9 \tTraining Loss: 2.229234   Test Accuracy: 17.420\n",
      "Epoch: 10 \tTraining Loss: 2.186216   Test Accuracy: 22.220\n",
      "Epoch: 11 \tTraining Loss: 2.141644   Test Accuracy: 25.500\n",
      "Epoch: 12 \tTraining Loss: 2.092237   Test Accuracy: 26.470\n",
      "Epoch: 13 \tTraining Loss: 2.030339   Test Accuracy: 28.070\n",
      "Epoch: 14 \tTraining Loss: 1.973105   Test Accuracy: 29.440\n",
      "Epoch: 15 \tTraining Loss: 1.929547   Test Accuracy: 31.220\n",
      "Epoch: 16 \tTraining Loss: 1.889619   Test Accuracy: 33.130\n",
      "Epoch: 17 \tTraining Loss: 1.847090   Test Accuracy: 34.410\n",
      "Epoch: 18 \tTraining Loss: 1.796732   Test Accuracy: 36.140\n",
      "Epoch: 19 \tTraining Loss: 1.744639   Test Accuracy: 37.650\n",
      "Epoch: 20 \tTraining Loss: 1.698760   Test Accuracy: 38.960\n",
      "Epoch: 21 \tTraining Loss: 1.661461   Test Accuracy: 39.530\n",
      "Epoch: 22 \tTraining Loss: 1.630565   Test Accuracy: 40.610\n",
      "Epoch: 23 \tTraining Loss: 1.604873   Test Accuracy: 41.420\n",
      "Epoch: 24 \tTraining Loss: 1.582286   Test Accuracy: 42.350\n",
      "Epoch: 25 \tTraining Loss: 1.563018   Test Accuracy: 43.130\n",
      "Epoch: 26 \tTraining Loss: 1.545657   Test Accuracy: 43.860\n",
      "Epoch: 27 \tTraining Loss: 1.530001   Test Accuracy: 45.190\n",
      "Epoch: 28 \tTraining Loss: 1.515910   Test Accuracy: 45.620\n",
      "Epoch: 29 \tTraining Loss: 1.500769   Test Accuracy: 46.410\n",
      "Epoch: 30 \tTraining Loss: 1.489010   Test Accuracy: 46.410\n",
      "Epoch: 31 \tTraining Loss: 1.477338   Test Accuracy: 46.830\n",
      "Epoch: 32 \tTraining Loss: 1.466799   Test Accuracy: 47.700\n",
      "Epoch: 33 \tTraining Loss: 1.456182   Test Accuracy: 47.720\n",
      "Epoch: 34 \tTraining Loss: 1.446592   Test Accuracy: 47.570\n",
      "Epoch: 35 \tTraining Loss: 1.437272   Test Accuracy: 48.390\n",
      "Epoch: 36 \tTraining Loss: 1.425573   Test Accuracy: 48.500\n",
      "Epoch: 37 \tTraining Loss: 1.417703   Test Accuracy: 49.210\n",
      "Epoch: 38 \tTraining Loss: 1.407557   Test Accuracy: 49.380\n",
      "Epoch: 39 \tTraining Loss: 1.397163   Test Accuracy: 50.340\n",
      "Epoch: 40 \tTraining Loss: 1.388653   Test Accuracy: 50.030\n",
      "Epoch: 41 \tTraining Loss: 1.379386   Test Accuracy: 50.730\n",
      "Epoch: 42 \tTraining Loss: 1.369628   Test Accuracy: 50.650\n",
      "Epoch: 43 \tTraining Loss: 1.360292   Test Accuracy: 50.920\n",
      "Epoch: 44 \tTraining Loss: 1.350326   Test Accuracy: 51.730\n",
      "Epoch: 45 \tTraining Loss: 1.342095   Test Accuracy: 51.800\n",
      "Epoch: 46 \tTraining Loss: 1.332043   Test Accuracy: 52.440\n",
      "Epoch: 47 \tTraining Loss: 1.323293   Test Accuracy: 52.380\n",
      "Epoch: 48 \tTraining Loss: 1.313499   Test Accuracy: 51.890\n",
      "Epoch: 49 \tTraining Loss: 1.304746   Test Accuracy: 53.170\n",
      "Epoch: 50 \tTraining Loss: 1.296331   Test Accuracy: 53.030\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "sgd_lenet = optim.SGD(lenet.parameters(), lr=1e-3) #SGD\n",
    "lenet_sgd, loss_sgd, acc_sgd = train_test(lenet, train_dl, test_dl, sgd_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(B). TRAINING LENET WITH SGD+MOMENTUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 2.278836   Test Accuracy: 24.400\n",
      "Epoch: 2 \tTraining Loss: 1.850428   Test Accuracy: 38.980\n",
      "Epoch: 3 \tTraining Loss: 1.589276   Test Accuracy: 44.020\n",
      "Epoch: 4 \tTraining Loss: 1.475928   Test Accuracy: 47.370\n",
      "Epoch: 5 \tTraining Loss: 1.396388   Test Accuracy: 49.550\n",
      "Epoch: 6 \tTraining Loss: 1.331649   Test Accuracy: 53.010\n",
      "Epoch: 7 \tTraining Loss: 1.277900   Test Accuracy: 55.610\n",
      "Epoch: 8 \tTraining Loss: 1.225606   Test Accuracy: 58.060\n",
      "Epoch: 9 \tTraining Loss: 1.183693   Test Accuracy: 57.440\n",
      "Epoch: 10 \tTraining Loss: 1.149505   Test Accuracy: 59.600\n",
      "Epoch: 11 \tTraining Loss: 1.118117   Test Accuracy: 60.490\n",
      "Epoch: 12 \tTraining Loss: 1.090882   Test Accuracy: 60.510\n",
      "Epoch: 13 \tTraining Loss: 1.066007   Test Accuracy: 62.720\n",
      "Epoch: 14 \tTraining Loss: 1.039286   Test Accuracy: 61.490\n",
      "Epoch: 15 \tTraining Loss: 1.013967   Test Accuracy: 63.040\n",
      "Epoch: 16 \tTraining Loss: 0.998496   Test Accuracy: 62.630\n",
      "Epoch: 17 \tTraining Loss: 0.976476   Test Accuracy: 63.180\n",
      "Epoch: 18 \tTraining Loss: 0.958014   Test Accuracy: 64.740\n",
      "Epoch: 19 \tTraining Loss: 0.939918   Test Accuracy: 64.910\n",
      "Epoch: 20 \tTraining Loss: 0.925083   Test Accuracy: 65.390\n",
      "Epoch: 21 \tTraining Loss: 0.907241   Test Accuracy: 65.550\n",
      "Epoch: 22 \tTraining Loss: 0.894304   Test Accuracy: 65.470\n",
      "Epoch: 23 \tTraining Loss: 0.880295   Test Accuracy: 65.600\n",
      "Epoch: 24 \tTraining Loss: 0.864343   Test Accuracy: 65.630\n",
      "Epoch: 25 \tTraining Loss: 0.850413   Test Accuracy: 67.060\n",
      "Epoch: 26 \tTraining Loss: 0.845090   Test Accuracy: 66.460\n",
      "Epoch: 27 \tTraining Loss: 0.831095   Test Accuracy: 67.370\n",
      "Epoch: 28 \tTraining Loss: 0.817471   Test Accuracy: 66.460\n",
      "Epoch: 29 \tTraining Loss: 0.807582   Test Accuracy: 67.230\n",
      "Epoch: 30 \tTraining Loss: 0.796291   Test Accuracy: 67.490\n",
      "Epoch: 31 \tTraining Loss: 0.787121   Test Accuracy: 66.200\n",
      "Epoch: 32 \tTraining Loss: 0.774951   Test Accuracy: 67.790\n",
      "Epoch: 33 \tTraining Loss: 0.764284   Test Accuracy: 67.670\n",
      "Epoch: 34 \tTraining Loss: 0.757466   Test Accuracy: 68.080\n",
      "Epoch: 35 \tTraining Loss: 0.745848   Test Accuracy: 67.240\n",
      "Epoch: 36 \tTraining Loss: 0.736375   Test Accuracy: 67.900\n",
      "Epoch: 37 \tTraining Loss: 0.730280   Test Accuracy: 68.000\n",
      "Epoch: 38 \tTraining Loss: 0.719717   Test Accuracy: 68.140\n",
      "Epoch: 39 \tTraining Loss: 0.715873   Test Accuracy: 67.870\n",
      "Epoch: 40 \tTraining Loss: 0.705310   Test Accuracy: 68.190\n",
      "Epoch: 41 \tTraining Loss: 0.700352   Test Accuracy: 68.470\n",
      "Epoch: 42 \tTraining Loss: 0.695098   Test Accuracy: 66.050\n",
      "Epoch: 43 \tTraining Loss: 0.685067   Test Accuracy: 67.740\n",
      "Epoch: 44 \tTraining Loss: 0.682456   Test Accuracy: 67.530\n",
      "Epoch: 45 \tTraining Loss: 0.672799   Test Accuracy: 67.910\n",
      "Epoch: 46 \tTraining Loss: 0.666910   Test Accuracy: 67.640\n",
      "Epoch: 47 \tTraining Loss: 0.663245   Test Accuracy: 67.290\n",
      "Epoch: 48 \tTraining Loss: 0.655870   Test Accuracy: 67.510\n",
      "Epoch: 49 \tTraining Loss: 0.649003   Test Accuracy: 68.070\n",
      "Epoch: 50 \tTraining Loss: 0.641843   Test Accuracy: 67.130\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "sgdm_lenet = optim.SGD(lenet.parameters(), lr=1e-3, momentum=0.9) #SGD with momentum\n",
    "lenet_sgdm, loss_sgdm, acc_sgdm = train_test(lenet, train_dl, test_dl, sgdm_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(C). TRAINING LENET WITH ADAGRAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.934985   Test Accuracy: 33.050\n",
      "Epoch: 2 \tTraining Loss: 1.807557   Test Accuracy: 35.500\n",
      "Epoch: 3 \tTraining Loss: 1.760149   Test Accuracy: 36.970\n",
      "Epoch: 4 \tTraining Loss: 1.728753   Test Accuracy: 37.820\n",
      "Epoch: 5 \tTraining Loss: 1.706745   Test Accuracy: 38.670\n",
      "Epoch: 6 \tTraining Loss: 1.688164   Test Accuracy: 39.160\n",
      "Epoch: 7 \tTraining Loss: 1.672609   Test Accuracy: 39.690\n",
      "Epoch: 8 \tTraining Loss: 1.658776   Test Accuracy: 40.320\n",
      "Epoch: 9 \tTraining Loss: 1.647318   Test Accuracy: 40.500\n",
      "Epoch: 10 \tTraining Loss: 1.636636   Test Accuracy: 41.250\n",
      "Epoch: 11 \tTraining Loss: 1.626778   Test Accuracy: 41.580\n",
      "Epoch: 12 \tTraining Loss: 1.617146   Test Accuracy: 41.650\n",
      "Epoch: 13 \tTraining Loss: 1.609347   Test Accuracy: 41.970\n",
      "Epoch: 14 \tTraining Loss: 1.602517   Test Accuracy: 42.200\n",
      "Epoch: 15 \tTraining Loss: 1.595558   Test Accuracy: 42.440\n",
      "Epoch: 16 \tTraining Loss: 1.588992   Test Accuracy: 42.860\n",
      "Epoch: 17 \tTraining Loss: 1.583499   Test Accuracy: 43.240\n",
      "Epoch: 18 \tTraining Loss: 1.577098   Test Accuracy: 43.510\n",
      "Epoch: 19 \tTraining Loss: 1.571674   Test Accuracy: 43.650\n",
      "Epoch: 20 \tTraining Loss: 1.567092   Test Accuracy: 43.830\n",
      "Epoch: 21 \tTraining Loss: 1.561378   Test Accuracy: 44.010\n",
      "Epoch: 22 \tTraining Loss: 1.557454   Test Accuracy: 44.270\n",
      "Epoch: 23 \tTraining Loss: 1.554182   Test Accuracy: 44.250\n",
      "Epoch: 24 \tTraining Loss: 1.548551   Test Accuracy: 44.430\n",
      "Epoch: 25 \tTraining Loss: 1.545773   Test Accuracy: 44.410\n",
      "Epoch: 26 \tTraining Loss: 1.541195   Test Accuracy: 44.720\n",
      "Epoch: 27 \tTraining Loss: 1.537931   Test Accuracy: 44.960\n",
      "Epoch: 28 \tTraining Loss: 1.533113   Test Accuracy: 45.370\n",
      "Epoch: 29 \tTraining Loss: 1.529304   Test Accuracy: 45.110\n",
      "Epoch: 30 \tTraining Loss: 1.526932   Test Accuracy: 45.270\n",
      "Epoch: 31 \tTraining Loss: 1.523065   Test Accuracy: 45.400\n",
      "Epoch: 32 \tTraining Loss: 1.520072   Test Accuracy: 45.470\n",
      "Epoch: 33 \tTraining Loss: 1.518356   Test Accuracy: 45.670\n",
      "Epoch: 34 \tTraining Loss: 1.515190   Test Accuracy: 45.900\n",
      "Epoch: 35 \tTraining Loss: 1.511878   Test Accuracy: 46.100\n",
      "Epoch: 36 \tTraining Loss: 1.508776   Test Accuracy: 45.970\n",
      "Epoch: 37 \tTraining Loss: 1.506760   Test Accuracy: 46.120\n",
      "Epoch: 38 \tTraining Loss: 1.504506   Test Accuracy: 46.450\n",
      "Epoch: 39 \tTraining Loss: 1.501314   Test Accuracy: 46.180\n",
      "Epoch: 40 \tTraining Loss: 1.498607   Test Accuracy: 46.340\n",
      "Epoch: 41 \tTraining Loss: 1.497240   Test Accuracy: 46.400\n",
      "Epoch: 42 \tTraining Loss: 1.494783   Test Accuracy: 46.590\n",
      "Epoch: 43 \tTraining Loss: 1.493697   Test Accuracy: 46.590\n",
      "Epoch: 44 \tTraining Loss: 1.490785   Test Accuracy: 46.720\n",
      "Epoch: 45 \tTraining Loss: 1.488953   Test Accuracy: 46.690\n",
      "Epoch: 46 \tTraining Loss: 1.485561   Test Accuracy: 46.990\n",
      "Epoch: 47 \tTraining Loss: 1.484035   Test Accuracy: 47.220\n",
      "Epoch: 48 \tTraining Loss: 1.481995   Test Accuracy: 47.190\n",
      "Epoch: 49 \tTraining Loss: 1.480499   Test Accuracy: 46.880\n",
      "Epoch: 50 \tTraining Loss: 1.479165   Test Accuracy: 47.460\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "ag_lenet = optim.Adagrad(lenet.parameters(), lr=1e-3) #Adagrad\n",
    "lenet_ag, loss_ag, acc_ag = train_test(lenet, train_dl, test_dl, ag_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(D). TRAINING LENET WITH RMSPROP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.569512   Test Accuracy: 50.670\n",
      "Epoch: 2 \tTraining Loss: 1.297219   Test Accuracy: 56.230\n",
      "Epoch: 3 \tTraining Loss: 1.182148   Test Accuracy: 57.400\n",
      "Epoch: 4 \tTraining Loss: 1.112889   Test Accuracy: 57.120\n",
      "Epoch: 5 \tTraining Loss: 1.052540   Test Accuracy: 60.780\n",
      "Epoch: 6 \tTraining Loss: 1.008444   Test Accuracy: 62.470\n",
      "Epoch: 7 \tTraining Loss: 0.970378   Test Accuracy: 63.160\n",
      "Epoch: 8 \tTraining Loss: 0.938523   Test Accuracy: 63.980\n",
      "Epoch: 9 \tTraining Loss: 0.910906   Test Accuracy: 65.590\n",
      "Epoch: 10 \tTraining Loss: 0.885886   Test Accuracy: 65.680\n",
      "Epoch: 11 \tTraining Loss: 0.861961   Test Accuracy: 65.070\n",
      "Epoch: 12 \tTraining Loss: 0.845622   Test Accuracy: 65.290\n",
      "Epoch: 13 \tTraining Loss: 0.827001   Test Accuracy: 65.210\n",
      "Epoch: 14 \tTraining Loss: 0.809636   Test Accuracy: 66.180\n",
      "Epoch: 15 \tTraining Loss: 0.795246   Test Accuracy: 66.370\n",
      "Epoch: 16 \tTraining Loss: 0.783995   Test Accuracy: 66.320\n",
      "Epoch: 17 \tTraining Loss: 0.769749   Test Accuracy: 66.230\n",
      "Epoch: 18 \tTraining Loss: 0.760249   Test Accuracy: 66.090\n",
      "Epoch: 19 \tTraining Loss: 0.753386   Test Accuracy: 65.400\n",
      "Epoch: 20 \tTraining Loss: 0.740296   Test Accuracy: 66.390\n",
      "Epoch: 21 \tTraining Loss: 0.735992   Test Accuracy: 65.020\n",
      "Epoch: 22 \tTraining Loss: 0.718965   Test Accuracy: 65.560\n",
      "Epoch: 23 \tTraining Loss: 0.716149   Test Accuracy: 67.000\n",
      "Epoch: 24 \tTraining Loss: 0.703405   Test Accuracy: 67.510\n",
      "Epoch: 25 \tTraining Loss: 0.696903   Test Accuracy: 66.060\n",
      "Epoch: 26 \tTraining Loss: 0.688187   Test Accuracy: 66.870\n",
      "Epoch: 27 \tTraining Loss: 0.683154   Test Accuracy: 66.630\n",
      "Epoch: 28 \tTraining Loss: 0.681215   Test Accuracy: 66.760\n",
      "Epoch: 29 \tTraining Loss: 0.670979   Test Accuracy: 64.870\n",
      "Epoch: 30 \tTraining Loss: 0.662121   Test Accuracy: 67.520\n",
      "Epoch: 31 \tTraining Loss: 0.658616   Test Accuracy: 66.390\n",
      "Epoch: 32 \tTraining Loss: 0.654164   Test Accuracy: 66.350\n",
      "Epoch: 33 \tTraining Loss: 0.650164   Test Accuracy: 66.780\n",
      "Epoch: 34 \tTraining Loss: 0.645254   Test Accuracy: 67.210\n",
      "Epoch: 35 \tTraining Loss: 0.637682   Test Accuracy: 67.100\n",
      "Epoch: 36 \tTraining Loss: 0.629968   Test Accuracy: 63.390\n",
      "Epoch: 37 \tTraining Loss: 0.623272   Test Accuracy: 66.030\n",
      "Epoch: 38 \tTraining Loss: 0.627736   Test Accuracy: 67.050\n",
      "Epoch: 39 \tTraining Loss: 0.618828   Test Accuracy: 66.760\n",
      "Epoch: 40 \tTraining Loss: 0.615138   Test Accuracy: 67.300\n",
      "Epoch: 41 \tTraining Loss: 0.612299   Test Accuracy: 65.660\n",
      "Epoch: 42 \tTraining Loss: 0.604615   Test Accuracy: 66.500\n",
      "Epoch: 43 \tTraining Loss: 0.600802   Test Accuracy: 65.780\n",
      "Epoch: 44 \tTraining Loss: 0.595200   Test Accuracy: 66.190\n",
      "Epoch: 45 \tTraining Loss: 0.592777   Test Accuracy: 66.020\n",
      "Epoch: 46 \tTraining Loss: 0.591598   Test Accuracy: 65.750\n",
      "Epoch: 47 \tTraining Loss: 0.588115   Test Accuracy: 65.980\n",
      "Epoch: 48 \tTraining Loss: 0.579507   Test Accuracy: 67.150\n",
      "Epoch: 49 \tTraining Loss: 0.578030   Test Accuracy: 66.930\n",
      "Epoch: 50 \tTraining Loss: 0.575849   Test Accuracy: 64.950\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "rms_lenet = optim.RMSprop(lenet.parameters(), lr=1e-3) #RMSprop\n",
    "lenet_rms, loss_rms, acc_rms = train_test(lenet, train_dl, test_dl, rms_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5(E). TRAINING LENET WITH ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 1.610249   Test Accuracy: 49.330\n",
      "Epoch: 2 \tTraining Loss: 1.305762   Test Accuracy: 54.540\n",
      "Epoch: 3 \tTraining Loss: 1.198563   Test Accuracy: 57.480\n",
      "Epoch: 4 \tTraining Loss: 1.127415   Test Accuracy: 60.190\n",
      "Epoch: 5 \tTraining Loss: 1.082566   Test Accuracy: 59.740\n",
      "Epoch: 6 \tTraining Loss: 1.037528   Test Accuracy: 62.270\n",
      "Epoch: 7 \tTraining Loss: 1.007054   Test Accuracy: 62.140\n",
      "Epoch: 8 \tTraining Loss: 0.975199   Test Accuracy: 62.880\n",
      "Epoch: 9 \tTraining Loss: 0.951073   Test Accuracy: 63.690\n",
      "Epoch: 10 \tTraining Loss: 0.926880   Test Accuracy: 65.230\n",
      "Epoch: 11 \tTraining Loss: 0.902628   Test Accuracy: 65.380\n",
      "Epoch: 12 \tTraining Loss: 0.891919   Test Accuracy: 65.420\n",
      "Epoch: 13 \tTraining Loss: 0.874810   Test Accuracy: 65.420\n",
      "Epoch: 14 \tTraining Loss: 0.856405   Test Accuracy: 64.700\n",
      "Epoch: 15 \tTraining Loss: 0.841723   Test Accuracy: 65.950\n",
      "Epoch: 16 \tTraining Loss: 0.829818   Test Accuracy: 66.500\n",
      "Epoch: 17 \tTraining Loss: 0.820007   Test Accuracy: 66.990\n",
      "Epoch: 18 \tTraining Loss: 0.807604   Test Accuracy: 66.340\n",
      "Epoch: 19 \tTraining Loss: 0.796734   Test Accuracy: 65.590\n",
      "Epoch: 20 \tTraining Loss: 0.786927   Test Accuracy: 66.310\n",
      "Epoch: 21 \tTraining Loss: 0.781171   Test Accuracy: 67.110\n",
      "Epoch: 22 \tTraining Loss: 0.775756   Test Accuracy: 66.710\n",
      "Epoch: 23 \tTraining Loss: 0.763169   Test Accuracy: 66.470\n",
      "Epoch: 24 \tTraining Loss: 0.757292   Test Accuracy: 66.640\n",
      "Epoch: 25 \tTraining Loss: 0.747640   Test Accuracy: 64.490\n",
      "Epoch: 26 \tTraining Loss: 0.739020   Test Accuracy: 66.190\n",
      "Epoch: 27 \tTraining Loss: 0.738886   Test Accuracy: 66.260\n",
      "Epoch: 28 \tTraining Loss: 0.727615   Test Accuracy: 66.920\n",
      "Epoch: 29 \tTraining Loss: 0.718744   Test Accuracy: 66.440\n",
      "Epoch: 30 \tTraining Loss: 0.716203   Test Accuracy: 65.880\n",
      "Epoch: 31 \tTraining Loss: 0.705929   Test Accuracy: 66.270\n",
      "Epoch: 32 \tTraining Loss: 0.698403   Test Accuracy: 66.250\n",
      "Epoch: 33 \tTraining Loss: 0.697053   Test Accuracy: 65.430\n",
      "Epoch: 34 \tTraining Loss: 0.695574   Test Accuracy: 66.630\n",
      "Epoch: 35 \tTraining Loss: 0.682591   Test Accuracy: 65.280\n",
      "Epoch: 36 \tTraining Loss: 0.680482   Test Accuracy: 65.860\n",
      "Epoch: 37 \tTraining Loss: 0.678467   Test Accuracy: 66.250\n",
      "Epoch: 38 \tTraining Loss: 0.669180   Test Accuracy: 66.600\n"
     ]
    }
   ],
   "source": [
    "lenet = LeNet().to(device)\n",
    "adam_lenet = optim.Adam(lenet.parameters(), lr=1e-3) #Adam\n",
    "lenet_adam, loss_adam, acc_adam = train_test(lenet, train_dl, test_dl, adam_lenet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(A). TRAINING ALEXNET WITH SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "sgd_alexnet = optim.SGD(alexnet.parameters(), lr=1e-3) #SGD\n",
    "alexnet_sgd, a_loss_sgd, a_acc_sgd = train_test(alexnet, train_dl, test_dl, sgd_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(B). TRAINING ALEXNET WITH SGD+MOMENTUM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "sgdm_alexnet = optim.SGD(alexnet.parameters(), lr=1e-3, momentum=0.9) #SGD+momentum\n",
    "alexnet_sgdm, a_loss_sgdm, a_acc_sgdm = train_test(alexnet, train_dl, test_dl, sgdm_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(C). TRAINING ALEXNET WITH ADAGRAD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "ag_alexnet = optim.Adagrad(alexnet.parameters(), lr=1e-3) #adagrad\n",
    "alexnet_ag, a_loss_ag, a_acc_ag = train_test(alexnet, train_dl, test_dl, ag_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(D). TRAINING ALEXNET WITH RMSPROP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "rms_alexnet = optim.RMSprop(alexnet.parameters(), lr=1e-3) #rmsprop\n",
    "alexnet_rms, a_loss_rms, a_acc_rms = train_test(alexnet, train_dl, test_dl, rms_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6(E). TRAINING ALEXNET WITH ADAM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "adam_alexnet = optim.Adam(alexnet.parameters(), lr=1e-3) #Adam\n",
    "alexnet_adam, a_loss_adam, a_acc_adam = train_test(alexnet, train_dl, test_dl, adam_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnet = AlexNet().to(device)\n",
    "adam_alexnet = optim.Adam(alexnet.parameters(), lr=1e-5) #Adam\n",
    "alexnet_adam, a_loss_adam, a_acc_adam = train_test(alexnet, train_dl, test_dl, adam_alexnet, n_epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PLOTTING THE RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_loss_sgd, label = \"sgd\")\n",
    "plt.plot(a_loss_sgdm, label = \"sgdm\")\n",
    "plt.plot(a_loss_ag, label = \"adagrad\")\n",
    "plt.plot(a_loss_rms, label = \"rmsprop\")\n",
    "plt.plot(a_loss_adam, label = \"adam\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"AlexNet train loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a_acc_sgd, label = \"sgd\")\n",
    "plt.plot(a_acc_sgdm, label = \"sgdm\")\n",
    "plt.plot(a_acc_ag, label = \"adagrad\")\n",
    "plt.plot(a_acc_rms, label = \"rmsprop\")\n",
    "plt.plot(a_acc_adam, label = \"adam\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.title(\"AlexNet test accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. FURTHER EXPERIMENTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77ea62aefc826ad60bd92e68cbd3f3114bc6d7e920db1ef6da6e6811c5006655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
